{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1947,
     "status": "ok",
     "timestamp": 1729889384359,
     "user": {
      "displayName": "Stefania Stefanska",
      "userId": "00621967363159764559"
     },
     "user_tz": -120
    },
    "id": "zF_Mo72VOCeJ",
    "outputId": "35c016f2-1276-4e25-e848-0e80fe56dfa3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 01:46:20.238658: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9373] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 01:46:20.238745: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 01:46:20.241051: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1534] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras import optimizers, metrics, losses\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "from keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout, ZeroPadding2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Conv1D,MaxPooling1D,Conv1DTranspose,AveragePooling1D,GlobalMaxPool1D,GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,Conv2DTranspose,AveragePooling2D,GlobalMaxPool2D,GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv3D,MaxPooling3D,Conv3DTranspose,AveragePooling3D,GlobalMaxPool3D,GlobalAveragePooling3D\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout,Concatenate,Layer,BatchNormalization,Input,Add,Activation,Average\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1729886578204,
     "user": {
      "displayName": "Stefania Stefanska",
      "userId": "00621967363159764559"
     },
     "user_tz": -120
    },
    "id": "IQApvVrKQnpZ",
    "outputId": "9696fe4d-9df8-48df-ef31-e47ad593bde3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/Tomasz/4T/work/dexined/outlineOutput/test_edge/*\n"
     ]
    }
   ],
   "source": [
    "#data_path = \"outlineOutput\"\n",
    "#H:\\\\download\\\\blender\\\\projects\\\\vdmTests\\\\outlineOutput2\"\n",
    "#output_path = \"H:\\\\tmp\\\\dexined\"\n",
    "\n",
    "data_path = \"/media/Tomasz/4T/work/dexined/outlineOutput\"\n",
    "output_path = \"/media/Tomasz/4T/work/dexined/tmp\"\n",
    "\n",
    "\n",
    "train_path = data_path + \"/train/*\"\n",
    "edge_train_path = data_path + \"/train_edge/*\"\n",
    "\n",
    "test_path = data_path + \"/test/*\"\n",
    "edge_test_path = data_path + \"/test_edge/*\"\n",
    "\n",
    "val_path = data_path + \"/val/*\"\n",
    "edge_val_path = data_path + \"/val_edge/*\"\n",
    "\n",
    "print(edge_test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Wfg4fFHzRJRw"
   },
   "outputs": [],
   "source": [
    "def load_data(ipath, epath):\n",
    "    images = sorted(glob(os.path.join(ipath)))\n",
    "    edges = sorted(glob(os.path.join(epath)))\n",
    "    return images, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QhsGIKuqRLxA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40598 4164\n"
     ]
    }
   ],
   "source": [
    "images, edges = load_data(train_path, edge_train_path)\n",
    "valimg, valedg = load_data(val_path, edge_val_path)\n",
    "print(len(images), len(valimg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1729886804972,
     "user": {
      "displayName": "Stefania Stefanska",
      "userId": "00621967363159764559"
     },
     "user_tz": -120
    },
    "id": "d6QAy1REROhL",
    "outputId": "21a8b0b9-76ca-485a-b3fd-dd4bd5f35db9"
   },
   "outputs": [],
   "source": [
    "#print(len(testimg), len(testedg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mucAnN8DSiX1"
   },
   "outputs": [],
   "source": [
    "def read_image(path, H=512, W=912):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (W,H))\n",
    "    x = x/255.0\n",
    "    x = x.astype(np.float32)\n",
    "    return x\n",
    "\n",
    "def read_edge(path, H=512, W=912):\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (W,H))\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    x = x/255.0\n",
    "    x = x.astype(np.float32)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1729890249446,
     "user": {
      "displayName": "Stefania Stefanska",
      "userId": "00621967363159764559"
     },
     "user_tz": -120
    },
    "id": "7hD4Ss0nTvs5",
    "outputId": "d1b776e6-8780-45c3-db5e-d8e27b287de8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xfffede37e770>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "img = read_edge(data_path+\"/train_edge/dense_000.png\", H=512, W=912)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rT9rmkNyVphm"
   },
   "outputs": [],
   "source": [
    "def preprocess(x,y,H=512, W=912):\n",
    "\n",
    "    def f(x,y):\n",
    "        x = x.decode()\n",
    "        y = y.decode()\n",
    "\n",
    "        x = read_image(x)\n",
    "        y = read_edge(y)\n",
    "        return x, y\n",
    "\n",
    "    images, edges = tf.numpy_function(f, [x, y], [tf.float32, tf.float32])\n",
    "    images.set_shape([H, W, 3])\n",
    "    edges.set_shape([H, W, 1])\n",
    "    return images, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KIwupAtAVvxY"
   },
   "outputs": [],
   "source": [
    "def tf_data(x,y,bs):\n",
    "    data = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    data = data.shuffle(buffer_size=bs)\n",
    "    data = data.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    data = data.batch(12)\n",
    "    data = data.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NFwyUh9tVyYn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 01:46:56.275562: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-07 01:46:56.301084: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-07 01:46:56.301297: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-07 01:46:56.303126: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-07 01:46:56.303331: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-07 01:46:56.303452: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-07 01:46:56.371149: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-07 01:46:56.371486: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-07 01:46:56.371552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-11-07 01:46:56.371720: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:00:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-07 01:46:56.371791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2469 MB memory:  -> device: 0, name: Orin, pci bus id: 0000:00:00.0, compute capability: 8.7\n"
     ]
    }
   ],
   "source": [
    "train_data = tf_data(images, edges, len(images))\n",
    "val_data = tf_data(valimg, valedg, len(valimg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecRC9seEV0zc"
   },
   "outputs": [],
   "source": [
    "#for x, y in train_data:\n",
    "#  print(x.shape, y.shape)\n",
    "#\n",
    "print(len(train_data),len(val_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_binary_cross_entropy(bc_loss,input, label, use_tf_loss=False):\n",
    "    # preprocess data\n",
    "    y = label\n",
    "    loss = 0\n",
    "    w_loss=1.0\n",
    "    preds = []\n",
    "    #for tmp_p in input:\n",
    "    # tmp_p = input[i]\n",
    "    tmp_p = input\n",
    "    # loss processing\n",
    "    tmp_y = tf.cast(y, dtype=tf.float32)\n",
    "    mask = tf.dtypes.cast(tmp_y > 0., tf.float32)\n",
    "    b,h,w,c=mask.get_shape()\n",
    "    positives = tf.math.reduce_sum(mask, axis=[1, 2, 3], keepdims=True)\n",
    "    negatives = h*w*c-positives\n",
    "\n",
    "    beta2 = (1.*positives) / (negatives + positives) # negatives in hed\n",
    "    beta = (1.1*negatives)/ (positives + negatives) # positives in hed\n",
    "    pos_w = tf.where(tf.equal(y, 0.0), beta2, beta)\n",
    "    logits = tf.sigmoid(tmp_p)\n",
    "\n",
    "    l_cost = bc_loss(y_true=tmp_y, y_pred=logits,\n",
    "                     sample_weight=pos_w)\n",
    "\n",
    "    preds.append(logits)\n",
    "    loss += (l_cost*w_loss)\n",
    "\n",
    "    return preds, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model,model_name,train_data,test_data,lr,beta1,max_epochs,batch_size):\n",
    "    # Validation and Train dataset generation\n",
    "\n",
    "    train_data = train_data\n",
    "    n_train =len(train_data) #data_cache[\"n_files\"]\n",
    "    val_data = test_data\n",
    "    \n",
    "    # Summary and checkpoint manager\n",
    "    model_dir = model_name\n",
    "    summary_dir = os.path.join(output_path,'logs',model_dir)\n",
    "    train_log_dir=os.path.join(summary_dir,'train')\n",
    "    val_log_dir =os.path.join(summary_dir,'test')\n",
    "\n",
    "    checkpoint_dir = os.path.join(output_path,\"checkpoint_dir\",model_dir)\n",
    "    epoch_ckpt_dir = checkpoint_dir + 'epochs'\n",
    "    os.makedirs(epoch_ckpt_dir, exist_ok=True)\n",
    "    os.makedirs(train_log_dir,exist_ok=True)\n",
    "    os.makedirs(val_log_dir,exist_ok=True)\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    train_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "    val_writer = tf.summary.create_file_writer(val_log_dir)\n",
    "\n",
    "    my_model = model\n",
    "\n",
    "    # accuracy = metrics.SparseCategoricalAccuracy()\n",
    "    accuracy = metrics.BinaryAccuracy()\n",
    "    accuracy_val = metrics.BinaryAccuracy()\n",
    "    loss_bc = losses.BinaryCrossentropy()\n",
    "    optimizer = optimizers.Adam(\n",
    "        learning_rate=lr, beta_1=beta1)\n",
    "    iter = 0\n",
    "\n",
    "    imgs_res_folder = os.path.join(output_path,model_dir, \"current_training\")\n",
    "    os.makedirs(imgs_res_folder, exist_ok=True)\n",
    "    global_loss = 1000.\n",
    "    t_loss = []\n",
    "    ckpt_save_mode = \"h5\"\n",
    "    tmp_lr = lr\n",
    "    for epoch in range(max_epochs):\n",
    "        # training\n",
    "        t_loss = []\n",
    "        # if epoch in self.args.adjust_lr:\n",
    "        tmp_lr=tmp_lr*0.1\n",
    "        optimizer.lr.assign(tmp_lr)\n",
    "        for step, (x, y) in enumerate(train_data):\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                pred = my_model(x, training=True)\n",
    "\n",
    "                preds, loss = pre_process_binary_cross_entropy(\n",
    "                    loss_bc, pred, y, use_tf_loss=False)\n",
    "\n",
    "            accuracy.update_state(y_true=y, y_pred=preds[-1])\n",
    "            gradients = tape.gradient(loss, my_model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, my_model.trainable_variables))\n",
    "\n",
    "            # logging the current accuracy value so far.\n",
    "            t_loss.append(loss.numpy())\n",
    "            if step % 10 == 0:\n",
    "                print(\"Epoch:\", epoch, \"Step:\", step, \"Loss: %.4f\" % loss.numpy(),\n",
    "                        \"Accuracy: %.4f\" % accuracy.result(), time.ctime())\n",
    "\n",
    "            #if step % 10 == 0:\n",
    "            #    # visualize preds\n",
    "            #    img_test = 'Epoch: {0} Sample {1}/{2} Loss: {3}' \\\n",
    "            #        .format(epoch, step, n_train // batch_size, loss.numpy())\n",
    "            #    vis_imgs = visualize_result(\n",
    "            #        x=x[2], y=y[2], p=preds, img_title=img_test)\n",
    "            #    cv.imwrite(os.path.join(imgs_res_folder, 'results.png'), vis_imgs)\n",
    "            if step % 20 == 0 and loss < global_loss:  # 500\n",
    "                if epoch==0 and step==0:\n",
    "                    tmp_loss = np.array(t_loss)\n",
    "                    with train_writer.as_default():\n",
    "                        tf.summary.scalar('loss', tmp_loss.mean(), step=epoch)\n",
    "                        tf.summary.scalar('accuracy', accuracy.result(), step=epoch)\n",
    "\n",
    "                save_ckpt_path = os.path.join(checkpoint_dir, \"DexiNedL_model.h5\")\n",
    "                Model.save_weights(my_model, save_ckpt_path, save_format='h5')\n",
    "\n",
    "                global_loss = loss\n",
    "                print(\"Model saved in:  \", save_ckpt_path, \"Current loss:\", global_loss.numpy())\n",
    "\n",
    "            iter += 1  # global iteration\n",
    "\n",
    "        t_loss = np.array(t_loss)\n",
    "        # train summary\n",
    "        if epoch!=0:\n",
    "            with train_writer.as_default():\n",
    "                tf.summary.scalar('loss', t_loss.mean(), step=epoch)\n",
    "                tf.summary.scalar('accuracy', accuracy.result(), step=epoch)\n",
    "\n",
    "        Model.save_weights(my_model, os.path.join(epoch_ckpt_dir, \"DexiNed{}_model.h5\".format(str(epoch))),\n",
    "                            save_format=ckpt_save_mode)\n",
    "        print(\"Epoch:\", epoch, \"Model saved in Loss: \", t_loss.mean())\n",
    "\n",
    "        # validation\n",
    "        t_val_loss = []\n",
    "        for i, (x_val, y_val) in enumerate(val_data):\n",
    "\n",
    "            pred_val = my_model(x_val)\n",
    "            v_logits, V_loss = pre_process_binary_cross_entropy(\n",
    "                loss_bc, pred_val, y_val, use_tf_loss=False)\n",
    "            accuracy_val.update_state(y_true=y_val, y_pred=v_logits[-1])\n",
    "            t_val_loss.append(V_loss.numpy())\n",
    "            if i == 7:\n",
    "                break\n",
    "        val_acc = accuracy_val.result()\n",
    "        t_val_loss = np.array(t_val_loss)\n",
    "        print(\"Epoch(validation):\", epoch, \"Val loss: \", t_val_loss.mean(),\n",
    "                \"Accuracy: \", val_acc.numpy())\n",
    "        # validation summary\n",
    "        with val_writer.as_default():\n",
    "            tf.summary.scalar('loss', t_val_loss.mean(), step=epoch)\n",
    "            tf.summary.scalar('accuracy', val_acc.numpy(), step=epoch)\n",
    "\n",
    "        # Reset metrics every epoch\n",
    "        accuracy.reset_states()\n",
    "        accuracy_val.reset_states()\n",
    "\n",
    "    my_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "arFATtCJWBT1"
   },
   "outputs": [],
   "source": [
    "weight_init = tf.initializers.glorot_uniform()\n",
    "\n",
    "l2 = regularizers.l2\n",
    "w_decay=1e-3\n",
    "\n",
    "glorot_normal = RandomNormal(stddev=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Lq8s_-1AXMP0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "self_conv2D_3 = Conv2D(32 , kernel_size=(3,3),strides=(2,2),padding = 'same',use_bias=True,kernel_initializer= glorot_normal)\n",
    "self_batchnormalization_24 = BatchNormalization()\n",
    "self_conv2D_40 = Conv2D(64 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True,kernel_initializer= glorot_normal)\n",
    "self_batchnormalization_18 = BatchNormalization()\n",
    "self_activation_11 = Activation(activation='relu')\n",
    "self_conv2D_1 = Conv2D(128 , kernel_size=(3,3),strides=(1,1),padding = 'same')\n",
    "self_conv2D_16 = Conv2D(128 , kernel_size=(1,1),strides=(2,2),padding = 'same',use_bias=True)\n",
    "self_conv2D_51 = Conv2D(1 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_1 = BatchNormalization()\n",
    "self_transpoze2D_9 = Conv2DTranspose(1 , kernel_size=(2,2),strides=(2,2),padding = 'same')\n",
    "self_conv2D_49 = Conv2D(128 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_8 = BatchNormalization()\n",
    "self_activation_1 = Activation(activation='relu')\n",
    "self_conv2D_17 = Conv2D(1 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_maxpool2D_1 = MaxPool2D(pool_size=(3,3),strides=(2,2),padding = 'same')\n",
    "self_transpoze2D_10 = Conv2DTranspose(1 , kernel_size=(2,2),strides=(2,2),padding = 'same')\n",
    "self_conv2D_28 = Conv2D(256 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_conv2D_36 = Conv2D(256 , kernel_size=(1,1),strides=(2,2),padding = 'same',use_bias=True)\n",
    "self_activation_8 = Activation(activation='relu')\n",
    "self_conv2D_47 = Conv2D(256 , kernel_size=(1,1),strides=(2,2),padding = 'same',use_bias=True)\n",
    "self_conv2D_48 = Conv2D(512 , kernel_size=(1,1),strides=(2,2),padding = 'same')\n",
    "self_conv2D_33 = Conv2D(256 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_6 = BatchNormalization()\n",
    "self_activation_9 = Activation(activation='relu')\n",
    "self_conv2D_31 = Conv2D(256 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_22 = BatchNormalization()\n",
    "self_activation_6 = Activation(activation='relu')\n",
    "self_conv2D_30 = Conv2D(256 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_4 = BatchNormalization()\n",
    "self_activation_7 = Activation(activation='relu')\n",
    "self_conv2D_18 = Conv2D(256 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_20 = BatchNormalization()\n",
    "self_conv2D_38 = Conv2D(16 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_maxpool2D_2 = MaxPool2D(pool_size=(3,3),strides=(2,2),padding = 'same')\n",
    "self_transpoze2D_15 = Conv2DTranspose(16 , kernel_size=(4,4),strides=(2,2),padding = 'same')\n",
    "self_conv2D_11 = Conv2D(1 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_conv2D_34 = Conv2D(512 , kernel_size=(1,1),strides=(2,2),padding = 'same',use_bias=True)\n",
    "self_conv2D_50 = Conv2D(512 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_transpoze2D_2 = Conv2DTranspose(1 , kernel_size=(4,4),strides=(2,2),padding = 'same')\n",
    "self_activation_10 = Activation(activation='relu')\n",
    "self_conv2D_32 = Conv2D(512 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_10 = BatchNormalization()\n",
    "self_activation_5 = Activation(activation='relu')\n",
    "self_conv2D_27 = Conv2D(512 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_19 = BatchNormalization()\n",
    "self_activation_24 = Activation(activation='relu')\n",
    "self_conv2D_26 = Conv2D(512 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_13 = BatchNormalization()\n",
    "self_activation_16 = Activation(activation='relu')\n",
    "self_conv2D_13 = Conv2D(512 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_17 = BatchNormalization()\n",
    "self_activation_22 = Activation(activation='relu')\n",
    "self_conv2D_29 = Conv2D(512 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_15 = BatchNormalization()\n",
    "self_activation_23 = Activation(activation='relu')\n",
    "self_conv2D_24 = Conv2D(512 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_12 = BatchNormalization()\n",
    "self_conv2D_44 = Conv2D(16 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_maxpool2D_3 = MaxPool2D(pool_size=(3,3),strides=(2,2),padding = 'same')\n",
    "self_transpoze2D_7 = Conv2DTranspose(16 , kernel_size=(8,8),strides=(2,2),padding = 'same')\n",
    "self_conv2D_45 = Conv2D(16 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_activation_15 = Activation(activation='relu')\n",
    "self_conv2D_6 = Conv2D(512 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_conv2D_2 = Conv2D(512 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_transpoze2D_8 = Conv2DTranspose(16 , kernel_size=(8,8),strides=(2,2),padding = 'same')\n",
    "self_conv2D_43 = Conv2D(512 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_conv2D_41 = Conv2D(1 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_7 = BatchNormalization()\n",
    "self_transpoze2D_14 = Conv2DTranspose(1 , kernel_size=(8,8),strides=(2,2),padding = 'same')\n",
    "self_activation_17 = Activation(activation='relu')\n",
    "self_conv2D_19 = Conv2D(512 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_16 = BatchNormalization()\n",
    "self_activation_13 = Activation(activation='relu')\n",
    "self_conv2D_21 = Conv2D(512 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_14 = BatchNormalization()\n",
    "self_activation_14 = Activation(activation='relu')\n",
    "self_conv2D_15 = Conv2D(512 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_5 = BatchNormalization()\n",
    "self_activation_18 = Activation(activation='relu')\n",
    "self_conv2D_14 = Conv2D(512 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_26 = BatchNormalization()\n",
    "self_activation_19 = Activation(activation='relu')\n",
    "self_conv2D_5 = Conv2D(512 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_3 = BatchNormalization()\n",
    "self_conv2D_8 = Conv2D(256 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_conv2D_35 = Conv2D(16 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_activation_20 = Activation(activation='relu')\n",
    "self_transpoze2D_4 = Conv2DTranspose(16 , kernel_size=(16,16),strides=(2,2),padding = 'same')\n",
    "self_conv2D_22 = Conv2D(256 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_conv2D_12 = Conv2D(16 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_11 = BatchNormalization()\n",
    "self_transpoze2D_12 = Conv2DTranspose(16 , kernel_size=(16,16),strides=(2,2),padding = 'same')\n",
    "self_activation_21 = Activation(activation='relu')\n",
    "self_conv2D_37 = Conv2D(16 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_conv2D_10 = Conv2D(256 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_transpoze2D_5 = Conv2DTranspose(16 , kernel_size=(16,16),strides=(2,2),padding = 'same')\n",
    "self_batchnormalization_21 = BatchNormalization()\n",
    "self_conv2D_42 = Conv2D(16 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_transpoze2D_13 = Conv2DTranspose(1 , kernel_size=(16,16),strides=(2,2),padding = 'same')\n",
    "self_activation_3 = Activation(activation='relu')\n",
    "self_conv2D_20 = Conv2D(256 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_9 = BatchNormalization()\n",
    "self_activation_4 = Activation(activation='relu')\n",
    "self_conv2D_23 = Conv2D(256 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_2 = BatchNormalization()\n",
    "self_activation_2 = Activation(activation='relu')\n",
    "self_conv2D_7 = Conv2D(256 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_23 = BatchNormalization()\n",
    "self_activation_12 = Activation(activation='relu')\n",
    "self_conv2D_25 = Conv2D(256 , kernel_size=(3,3),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_batchnormalization_25 = BatchNormalization()\n",
    "self_conv2D_39 = Conv2D(16 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_transpoze2D_11 = Conv2DTranspose(16 , kernel_size=(16,16),strides=(2,2),padding = 'same')\n",
    "self_conv2D_4 = Conv2D(16 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_transpoze2D_3 = Conv2DTranspose(16 , kernel_size=(16,16),strides=(2,2),padding = 'same')\n",
    "self_conv2D_9 = Conv2D(16 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_transpoze2D_6 = Conv2DTranspose(16 , kernel_size=(16,16),strides=(2,2),padding = 'same')\n",
    "self_conv2D_46 = Conv2D(1 , kernel_size=(1,1),strides=(1,1),padding = 'same',use_bias=True)\n",
    "self_transpoze2D_1 = Conv2DTranspose(1 , kernel_size=(16,16),strides=(2,2),padding = 'same')\n",
    "#self_block_cat = SingleConvBlock(\n",
    "#    1,k_size=(1,1),stride=(1,1),\n",
    "#    w_init=tf.constant_initializer(1/5))\n",
    "\n",
    "self_last_conv = Conv2D(1, kernel_size=(1,1), strides=(1,1), padding = 'same', kernel_initializer=tf.constant_initializer(1/5))\n",
    "self_last_batchnormalization = BatchNormalization()\n",
    "self_last_activation = Activation(activation='relu')\n",
    "\n",
    "#-------------------------------------\n",
    "\n",
    "x = Input(shape=(512,912,3))\n",
    "conv2D_3 = self_conv2D_3(x)\n",
    "batchnormalization_24 = self_batchnormalization_24(conv2D_3)\n",
    "conv2D_40 = self_conv2D_40(batchnormalization_24)\n",
    "batchnormalization_18 = self_batchnormalization_18(conv2D_40)\n",
    "activation_11 = self_activation_11(batchnormalization_18)\n",
    "conv2D_1 = self_conv2D_1(activation_11)\n",
    "conv2D_16 = self_conv2D_16(activation_11)\n",
    "conv2D_51 = self_conv2D_51(activation_11)\n",
    "batchnormalization_1 = self_batchnormalization_1(conv2D_1)\n",
    "transpoze2D_9 = self_transpoze2D_9(conv2D_51)\n",
    "conv2D_49 = self_conv2D_49(batchnormalization_1)\n",
    "batchnormalization_8 = self_batchnormalization_8(conv2D_49)\n",
    "activation_1 = self_activation_1(batchnormalization_8)\n",
    "conv2D_17 = self_conv2D_17(activation_1)\n",
    "maxpool2D_1 = self_maxpool2D_1(activation_1)\n",
    "transpoze2D_10 = self_transpoze2D_10(conv2D_17)\n",
    "add_1 = Add()([conv2D_16,maxpool2D_1])\n",
    "conv2D_28 = self_conv2D_28(maxpool2D_1)\n",
    "conv2D_36 = self_conv2D_36(maxpool2D_1)\n",
    "activation_8 = self_activation_8(add_1)\n",
    "conv2D_47 = self_conv2D_47(add_1)\n",
    "conv2D_48 = self_conv2D_48(conv2D_36)\n",
    "conv2D_33 = self_conv2D_33(activation_8)\n",
    "batchnormalization_6 = self_batchnormalization_6(conv2D_33)\n",
    "activation_9 = self_activation_9(batchnormalization_6)\n",
    "conv2D_31 = self_conv2D_31(activation_9)\n",
    "batchnormalization_22 = self_batchnormalization_22(conv2D_31)\n",
    "average_5 = Average()([batchnormalization_22,conv2D_28])\n",
    "activation_6 = self_activation_6(average_5)\n",
    "conv2D_30 = self_conv2D_30(activation_6)\n",
    "batchnormalization_4 = self_batchnormalization_4(conv2D_30)\n",
    "activation_7 = self_activation_7(batchnormalization_4)\n",
    "conv2D_18 = self_conv2D_18(activation_7)\n",
    "batchnormalization_20 = self_batchnormalization_20(conv2D_18)\n",
    "average_4 = Average()([batchnormalization_20,conv2D_28])\n",
    "conv2D_38 = self_conv2D_38(average_4)\n",
    "maxpool2D_2 = self_maxpool2D_2(average_4)\n",
    "transpoze2D_15 = self_transpoze2D_15(conv2D_38)\n",
    "add_2 = Add()([conv2D_47,maxpool2D_2])\n",
    "add_4 = Add()([conv2D_36,maxpool2D_2])\n",
    "conv2D_11 = self_conv2D_11(transpoze2D_15)\n",
    "conv2D_34 = self_conv2D_34(add_2)\n",
    "conv2D_50 = self_conv2D_50(add_4)\n",
    "transpoze2D_2 = self_transpoze2D_2(conv2D_11)\n",
    "activation_10 = self_activation_10(add_2)\n",
    "conv2D_32 = self_conv2D_32(activation_10)\n",
    "batchnormalization_10 = self_batchnormalization_10(conv2D_32)\n",
    "activation_5 = self_activation_5(batchnormalization_10)\n",
    "conv2D_27 = self_conv2D_27(activation_5)\n",
    "batchnormalization_19 = self_batchnormalization_19(conv2D_27)\n",
    "average_3 = Average()([batchnormalization_19,conv2D_50])\n",
    "activation_24 = self_activation_24(average_3)\n",
    "conv2D_26 = self_conv2D_26(activation_24)\n",
    "batchnormalization_13 = self_batchnormalization_13(conv2D_26)\n",
    "activation_16 = self_activation_16(batchnormalization_13)\n",
    "conv2D_13 = self_conv2D_13(activation_16)\n",
    "batchnormalization_17 = self_batchnormalization_17(conv2D_13)\n",
    "average_2 = Average()([batchnormalization_17,conv2D_50])\n",
    "activation_22 = self_activation_22(average_2)\n",
    "conv2D_29 = self_conv2D_29(activation_22)\n",
    "batchnormalization_15 = self_batchnormalization_15(conv2D_29)\n",
    "activation_23 = self_activation_23(batchnormalization_15)\n",
    "conv2D_24 = self_conv2D_24(activation_23)\n",
    "batchnormalization_12 = self_batchnormalization_12(conv2D_24)\n",
    "average_11 = Average()([batchnormalization_12,conv2D_50])\n",
    "conv2D_44 = self_conv2D_44(average_11)\n",
    "maxpool2D_3 = self_maxpool2D_3(average_11)\n",
    "transpoze2D_7 = self_transpoze2D_7(conv2D_44)\n",
    "add_3 = Add()([conv2D_34,maxpool2D_3])\n",
    "add_5 = Add()([conv2D_48,maxpool2D_3])\n",
    "conv2D_45 = self_conv2D_45(transpoze2D_7)\n",
    "activation_15 = self_activation_15(add_3)\n",
    "conv2D_6 = self_conv2D_6(add_3)\n",
    "conv2D_2 = self_conv2D_2(add_5)\n",
    "transpoze2D_8 = self_transpoze2D_8(conv2D_45)\n",
    "conv2D_43 = self_conv2D_43(activation_15)\n",
    "conv2D_41 = self_conv2D_41(transpoze2D_8)\n",
    "batchnormalization_7 = self_batchnormalization_7(conv2D_43)\n",
    "transpoze2D_14 = self_transpoze2D_14(conv2D_41)\n",
    "activation_17 = self_activation_17(batchnormalization_7)\n",
    "conv2D_19 = self_conv2D_19(activation_17)\n",
    "batchnormalization_16 = self_batchnormalization_16(conv2D_19)\n",
    "average_7 = Average()([batchnormalization_16,conv2D_2])\n",
    "activation_13 = self_activation_13(average_7)\n",
    "conv2D_21 = self_conv2D_21(activation_13)\n",
    "batchnormalization_14 = self_batchnormalization_14(conv2D_21)\n",
    "activation_14 = self_activation_14(batchnormalization_14)\n",
    "conv2D_15 = self_conv2D_15(activation_14)\n",
    "batchnormalization_5 = self_batchnormalization_5(conv2D_15)\n",
    "average_6 = Average()([batchnormalization_5,conv2D_2])\n",
    "activation_18 = self_activation_18(average_6)\n",
    "conv2D_14 = self_conv2D_14(activation_18)\n",
    "batchnormalization_26 = self_batchnormalization_26(conv2D_14)\n",
    "activation_19 = self_activation_19(batchnormalization_26)\n",
    "conv2D_5 = self_conv2D_5(activation_19)\n",
    "batchnormalization_3 = self_batchnormalization_3(conv2D_5)\n",
    "average_1 = Average()([batchnormalization_3,conv2D_2])\n",
    "add_6 = Add()([average_1,conv2D_6])\n",
    "conv2D_8 = self_conv2D_8(average_1)\n",
    "conv2D_35 = self_conv2D_35(average_1)\n",
    "activation_20 = self_activation_20(add_6)\n",
    "transpoze2D_4 = self_transpoze2D_4(conv2D_35)\n",
    "conv2D_22 = self_conv2D_22(activation_20)\n",
    "conv2D_12 = self_conv2D_12(transpoze2D_4)\n",
    "batchnormalization_11 = self_batchnormalization_11(conv2D_22)\n",
    "transpoze2D_12 = self_transpoze2D_12(conv2D_12)\n",
    "activation_21 = self_activation_21(batchnormalization_11)\n",
    "conv2D_37 = self_conv2D_37(transpoze2D_12)\n",
    "conv2D_10 = self_conv2D_10(activation_21)\n",
    "transpoze2D_5 = self_transpoze2D_5(conv2D_37)\n",
    "batchnormalization_21 = self_batchnormalization_21(conv2D_10)\n",
    "conv2D_42 = self_conv2D_42(transpoze2D_5)\n",
    "average_10 = Average()([batchnormalization_21,conv2D_8])\n",
    "transpoze2D_13 = self_transpoze2D_13(conv2D_42)\n",
    "activation_3 = self_activation_3(average_10)\n",
    "conv2D_20 = self_conv2D_20(activation_3)\n",
    "batchnormalization_9 = self_batchnormalization_9(conv2D_20)\n",
    "activation_4 = self_activation_4(batchnormalization_9)\n",
    "conv2D_23 = self_conv2D_23(activation_4)\n",
    "batchnormalization_2 = self_batchnormalization_2(conv2D_23)\n",
    "average_9 = Average()([batchnormalization_2,conv2D_8])\n",
    "activation_2 = self_activation_2(average_9)\n",
    "conv2D_7 = self_conv2D_7(activation_2)\n",
    "batchnormalization_23 = self_batchnormalization_23(conv2D_7)\n",
    "activation_12 = self_activation_12(batchnormalization_23)\n",
    "conv2D_25 = self_conv2D_25(activation_12)\n",
    "batchnormalization_25 = self_batchnormalization_25(conv2D_25)\n",
    "average_8 = Average()([batchnormalization_25,conv2D_8])\n",
    "conv2D_39 = self_conv2D_39(average_8)\n",
    "transpoze2D_11 = self_transpoze2D_11(conv2D_39)\n",
    "conv2D_4 = self_conv2D_4(transpoze2D_11)\n",
    "transpoze2D_3 = self_transpoze2D_3(conv2D_4)\n",
    "conv2D_9 = self_conv2D_9(transpoze2D_3)\n",
    "transpoze2D_6 = self_transpoze2D_6(conv2D_9)\n",
    "conv2D_46 = self_conv2D_46(transpoze2D_6)\n",
    "transpoze2D_1 = self_transpoze2D_1(conv2D_46)\n",
    "#tmp = [transpoze2D_1,transpoze2D_2,transpoze2D_9,transpoze2D_10,transpoze2D_13,transpoze2D_14]\n",
    "tmp = [transpoze2D_9,transpoze2D_10,transpoze2D_2,transpoze2D_14,transpoze2D_13,transpoze2D_1]\n",
    "\n",
    "#-----------\n",
    "#concatenate_1 = tf.concat(tmp,3)\n",
    "#-----------\n",
    "#concat_lambda = lambda xs: tf.concat(xs, axis=3)\n",
    "#concatenate_1 = tf.keras.layers.Lambda(concat_lambda)(tmp,3)\n",
    "#-----------\n",
    "self_concatenate_1 = Concatenate(axis=3)\n",
    "concatenate_1 = self_concatenate_1(tmp)\n",
    "\n",
    "#print(f\"concatenate_1 shape: {concatenate_1.shape}\")\n",
    "#return concatenate_1\n",
    "\n",
    "#results = [transpoze2D_1,transpoze2D_2,transpoze2D_9,transpoze2D_10,transpoze2D_13,transpoze2D_14]\n",
    "#block_cat = tf.concat(results, 3)  # BxHxWX6\n",
    "#print(f\"CONCATENATE_1 shape: {block_cat.shape}\")\n",
    "#block_cat = self_block_cat(block_cat)  # BxHxWX1\n",
    "#results.append(block_cat)\n",
    "\n",
    "\n",
    "last_conv =self_last_conv(concatenate_1)\n",
    "last_batchnormalization = self_last_batchnormalization(last_conv)\n",
    "last_activation = self_last_activation(last_batchnormalization)\n",
    "#concatenate_1 = Concatenate()([transpoze2D_1,transpoze2D_3,transpoze2D_4,transpoze2D_7,transpoze2D_8,transpoze2D_10])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs =x , outputs=last_activation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1729890283689,
     "user": {
      "displayName": "Stefania Stefanska",
      "userId": "00621967363159764559"
     },
     "user_tz": -120
    },
    "id": "g_bWv5rBXPZZ",
    "outputId": "e1a999c8-4b01-4474-dba7-ed12e6749b35"
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-RF4tlYwf3P3"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\", run_eagerly=True) #,\n",
    "    #metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
    "     #        tf.keras.metrics.FalseNegatives(),\n",
    "      #       tf.keras.metrics.FalsePositives(),\n",
    "       #      tf.keras.metrics.TruePositives(),\n",
    "        #    tf.keras.metrics.TrueNegatives()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 01:47:27.296058: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:467] Loaded cuDNN version 8904\n",
      "2024-11-07 01:47:35.309181: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 342.28MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-07 01:47:35.309435: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 342.28MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-07 01:47:35.309532: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 342.28MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-07 01:47:35.309609: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 342.28MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-07 01:47:35.309676: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 342.28MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-07 01:47:35.309742: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 342.28MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-07 01:47:35.309807: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 342.28MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-07 01:47:35.309869: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 342.28MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-07 01:47:35.309934: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 342.28MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-07 01:47:35.310002: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 342.28MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-11-07 01:47:35.312876: W tensorflow/core/kernels/conv_ops_gpu.cc:322] None of the algorithms provided by cuDNN frontend heuristics worked; trying fallback algorithms.  Conv: batch: 12\n",
      "in_depths: 64\n",
      "out_depths: 128\n",
      "in: 256\n",
      "in: 456\n",
      "filter: 3\n",
      "filter: 3\n",
      "filter: 64\n",
      "dilation: 1\n",
      "dilation: 1\n",
      "stride: 1\n",
      "stride: 1\n",
      "padding: 1\n",
      "padding: 1\n",
      "dtype: DT_FLOAT\n",
      "group_count: 1\n",
      "device_identifier: \"sm_8.7 with 65893896192B RAM, 8 cores, 1300000KHz clock, 612000KHz mem clock, 4194304B L2$\"\n",
      "version: 3\n",
      "\n",
      "2024-11-07 01:48:12.430118: W external/local_tsl/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 684.00MiB (rounded to 717225984)requested by op BiasAdd\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-11-07 01:48:12.430225: I external/local_tsl/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2024-11-07 01:48:12.430246: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 127, Chunks in use: 127. 31.8KiB allocated for chunks. 31.8KiB in use in bin. 5.7KiB client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430256: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 12, Chunks in use: 12. 6.0KiB allocated for chunks. 6.0KiB in use in bin. 6.0KiB client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430263: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 62, Chunks in use: 62. 63.8KiB allocated for chunks. 63.8KiB in use in bin. 62.0KiB client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430272: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 66, Chunks in use: 66. 137.5KiB allocated for chunks. 137.5KiB in use in bin. 133.4KiB client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430280: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 1, Chunks in use: 0. 4.8KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430286: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430293: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 5, Chunks in use: 4. 91.2KiB allocated for chunks. 64.0KiB in use in bin. 64.0KiB client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430300: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 3, Chunks in use: 3. 127.5KiB allocated for chunks. 127.5KiB in use in bin. 96.0KiB client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430307: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 3, Chunks in use: 3. 200.0KiB allocated for chunks. 200.0KiB in use in bin. 200.0KiB client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430314: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 4, Chunks in use: 3. 591.8KiB allocated for chunks. 384.0KiB in use in bin. 384.0KiB client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430321: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 9, Chunks in use: 7. 2.41MiB allocated for chunks. 1.91MiB in use in bin. 1.78MiB client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430327: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 5, Chunks in use: 5. 2.56MiB allocated for chunks. 2.56MiB in use in bin. 2.56MiB client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430333: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 3, Chunks in use: 3. 3.38MiB allocated for chunks. 3.38MiB in use in bin. 3.12MiB client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430340: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 10, Chunks in use: 8. 22.25MiB allocated for chunks. 18.00MiB in use in bin. 18.00MiB client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430347: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 2, Chunks in use: 2. 9.00MiB allocated for chunks. 9.00MiB in use in bin. 9.00MiB client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430354: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 11, Chunks in use: 11. 99.00MiB allocated for chunks. 99.00MiB in use in bin. 99.00MiB client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430359: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430365: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430383: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 1. 64.12MiB allocated for chunks. 64.12MiB in use in bin. 64.12MiB client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430391: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 3, Chunks in use: 2. 555.30MiB allocated for chunks. 342.00MiB in use in bin. 342.00MiB client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430398: I external/local_tsl/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 4, Chunks in use: 3. 1.67GiB allocated for chunks. 1.34GiB in use in bin. 1.34GiB client-requested in use in bin.\n",
      "2024-11-07 01:48:12.430405: I external/local_tsl/tsl/framework/bfc_allocator.cc:1062] Bin for 684.00MiB was 256.00MiB, Chunk State: \n",
      "2024-11-07 01:48:12.430426: I external/local_tsl/tsl/framework/bfc_allocator.cc:1068]   Size: 342.00MiB | Requested Size: 342.00MiB | in_use: 0 | bin_num: 20, prev:   Size: 171.00MiB | Requested Size: 171.00MiB | in_use: 1 | bin_num: -1, next:   Size: 342.00MiB | Requested Size: 342.00MiB | in_use: 1 | bin_num: -1\n",
      "2024-11-07 01:48:12.430433: I external/local_tsl/tsl/framework/bfc_allocator.cc:1075] Next region of size 2589188096\n",
      "2024-11-07 01:48:12.430442: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eae000 of size 1280 next 1\n",
      "2024-11-07 01:48:12.430448: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eae500 of size 256 next 2\n",
      "2024-11-07 01:48:12.430453: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eae600 of size 256 next 3\n",
      "2024-11-07 01:48:12.430458: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eae700 of size 256 next 4\n",
      "2024-11-07 01:48:12.430463: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eae800 of size 256 next 5\n",
      "2024-11-07 01:48:12.430468: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eae900 of size 256 next 6\n",
      "2024-11-07 01:48:12.430473: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eaea00 of size 256 next 7\n",
      "2024-11-07 01:48:12.430479: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eaeb00 of size 256 next 8\n",
      "2024-11-07 01:48:12.430484: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eaec00 of size 256 next 9\n",
      "2024-11-07 01:48:12.430490: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eaed00 of size 256 next 11\n",
      "2024-11-07 01:48:12.430495: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eaee00 of size 256 next 12\n",
      "2024-11-07 01:48:12.430500: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eaef00 of size 256 next 10\n",
      "2024-11-07 01:48:12.430505: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eaf000 of size 256 next 15\n",
      "2024-11-07 01:48:12.430510: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eaf100 of size 256 next 16\n",
      "2024-11-07 01:48:12.430515: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eaf200 of size 256 next 17\n",
      "2024-11-07 01:48:12.430521: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eaf300 of size 256 next 18\n",
      "2024-11-07 01:48:12.430526: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eaf400 of size 256 next 21\n",
      "2024-11-07 01:48:12.430531: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eaf500 of size 256 next 19\n",
      "2024-11-07 01:48:12.430536: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eaf600 of size 256 next 20\n",
      "2024-11-07 01:48:12.430541: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eaf700 of size 256 next 24\n",
      "2024-11-07 01:48:12.430546: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eaf800 of size 256 next 25\n",
      "2024-11-07 01:48:12.430551: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eaf900 of size 256 next 26\n",
      "2024-11-07 01:48:12.430557: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eafa00 of size 256 next 27\n",
      "2024-11-07 01:48:12.430562: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eafb00 of size 512 next 30\n",
      "2024-11-07 01:48:12.430568: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eafd00 of size 256 next 28\n",
      "2024-11-07 01:48:12.430573: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eafe00 of size 256 next 29\n",
      "2024-11-07 01:48:12.430578: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eaff00 of size 512 next 35\n",
      "2024-11-07 01:48:12.430583: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb0100 of size 256 next 33\n",
      "2024-11-07 01:48:12.430588: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb0200 of size 256 next 34\n",
      "2024-11-07 01:48:12.430593: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb0300 of size 256 next 39\n",
      "2024-11-07 01:48:12.430598: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb0400 of size 512 next 40\n",
      "2024-11-07 01:48:12.430604: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb0600 of size 256 next 41\n",
      "2024-11-07 01:48:12.430609: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb0700 of size 512 next 38\n",
      "2024-11-07 01:48:12.430614: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb0900 of size 512 next 13\n",
      "2024-11-07 01:48:12.430619: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb0b00 of size 3584 next 14\n",
      "2024-11-07 01:48:12.430625: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb1900 of size 2048 next 130\n",
      "2024-11-07 01:48:12.430630: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb2100 of size 2048 next 134\n",
      "2024-11-07 01:48:12.430636: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb2900 of size 256 next 135\n",
      "2024-11-07 01:48:12.430641: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb2a00 of size 256 next 136\n",
      "2024-11-07 01:48:12.430646: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb2b00 of size 2048 next 137\n",
      "2024-11-07 01:48:12.430651: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb3300 of size 2048 next 138\n",
      "2024-11-07 01:48:12.430656: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb3b00 of size 2048 next 141\n",
      "2024-11-07 01:48:12.430661: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb4300 of size 2048 next 142\n",
      "2024-11-07 01:48:12.430667: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb4b00 of size 3584 next 116\n",
      "2024-11-07 01:48:12.430672: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb5900 of size 16384 next 112\n",
      "2024-11-07 01:48:12.430677: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eb9900 of size 16384 next 111\n",
      "2024-11-07 01:48:12.430682: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ebd900 of size 2048 next 143\n",
      "2024-11-07 01:48:12.430687: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ebe100 of size 2048 next 144\n",
      "2024-11-07 01:48:12.430693: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ebe900 of size 2048 next 146\n",
      "2024-11-07 01:48:12.430698: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ebf100 of size 2048 next 147\n",
      "2024-11-07 01:48:12.430703: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ebf900 of size 2048 next 148\n",
      "2024-11-07 01:48:12.430708: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ec0100 of size 2048 next 149\n",
      "2024-11-07 01:48:12.430713: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ec0900 of size 2048 next 150\n",
      "2024-11-07 01:48:12.430720: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ec1100 of size 2048 next 37\n",
      "2024-11-07 01:48:12.430726: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ec1900 of size 32768 next 36\n",
      "2024-11-07 01:48:12.430731: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ec9900 of size 512 next 42\n",
      "2024-11-07 01:48:12.430736: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ec9b00 of size 256 next 43\n",
      "2024-11-07 01:48:12.430741: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ec9c00 of size 256 next 44\n",
      "2024-11-07 01:48:12.430747: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ec9d00 of size 256 next 46\n",
      "2024-11-07 01:48:12.430752: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ec9e00 of size 256 next 45\n",
      "2024-11-07 01:48:12.430757: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ec9f00 of size 256 next 47\n",
      "2024-11-07 01:48:12.430762: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eca000 of size 256 next 48\n",
      "2024-11-07 01:48:12.430767: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eca100 of size 512 next 49\n",
      "2024-11-07 01:48:12.430772: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eca300 of size 512 next 50\n",
      "2024-11-07 01:48:12.430777: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eca500 of size 512 next 53\n",
      "2024-11-07 01:48:12.430782: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eca700 of size 512 next 54\n",
      "2024-11-07 01:48:12.430787: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eca900 of size 512 next 55\n",
      "2024-11-07 01:48:12.430792: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecab00 of size 256 next 56\n",
      "2024-11-07 01:48:12.430797: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecac00 of size 256 next 57\n",
      "2024-11-07 01:48:12.430802: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecad00 of size 256 next 59\n",
      "2024-11-07 01:48:12.430808: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecae00 of size 256 next 60\n",
      "2024-11-07 01:48:12.430813: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecaf00 of size 256 next 72\n",
      "2024-11-07 01:48:12.430818: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecb000 of size 256 next 61\n",
      "2024-11-07 01:48:12.430823: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecb100 of size 256 next 64\n",
      "2024-11-07 01:48:12.430828: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecb200 of size 256 next 58\n",
      "2024-11-07 01:48:12.430833: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecb300 of size 256 next 62\n",
      "2024-11-07 01:48:12.430838: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecb400 of size 512 next 63\n",
      "2024-11-07 01:48:12.430843: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecb600 of size 1024 next 66\n",
      "2024-11-07 01:48:12.430849: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecba00 of size 1024 next 65\n",
      "2024-11-07 01:48:12.430854: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecbe00 of size 1024 next 69\n",
      "2024-11-07 01:48:12.430859: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecc200 of size 2048 next 75\n",
      "2024-11-07 01:48:12.430864: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecca00 of size 256 next 73\n",
      "2024-11-07 01:48:12.430869: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eccb00 of size 256 next 74\n",
      "2024-11-07 01:48:12.430874: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eccc00 of size 1024 next 80\n",
      "2024-11-07 01:48:12.430879: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecd000 of size 1024 next 78\n",
      "2024-11-07 01:48:12.430886: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecd400 of size 1024 next 79\n",
      "2024-11-07 01:48:12.430891: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecd800 of size 1024 next 83\n",
      "2024-11-07 01:48:12.430897: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecdc00 of size 1024 next 84\n",
      "2024-11-07 01:48:12.430902: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ece000 of size 256 next 85\n",
      "2024-11-07 01:48:12.430907: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ece100 of size 256 next 86\n",
      "2024-11-07 01:48:12.430912: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ece200 of size 1024 next 87\n",
      "2024-11-07 01:48:12.430917: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ece600 of size 1024 next 88\n",
      "2024-11-07 01:48:12.430922: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecea00 of size 1024 next 91\n",
      "2024-11-07 01:48:12.430927: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecee00 of size 1024 next 92\n",
      "2024-11-07 01:48:12.430932: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecf200 of size 1024 next 93\n",
      "2024-11-07 01:48:12.430938: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecf600 of size 1024 next 94\n",
      "2024-11-07 01:48:12.430943: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecfa00 of size 1024 next 95\n",
      "2024-11-07 01:48:12.430948: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ecfe00 of size 1024 next 97\n",
      "2024-11-07 01:48:12.430953: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed0200 of size 1024 next 98\n",
      "2024-11-07 01:48:12.430959: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed0600 of size 1024 next 99\n",
      "2024-11-07 01:48:12.430964: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed0a00 of size 1024 next 100\n",
      "2024-11-07 01:48:12.430970: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed0e00 of size 1024 next 101\n",
      "2024-11-07 01:48:12.430975: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed1200 of size 1024 next 103\n",
      "2024-11-07 01:48:12.430980: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed1600 of size 1024 next 104\n",
      "2024-11-07 01:48:12.430985: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed1a00 of size 1024 next 105\n",
      "2024-11-07 01:48:12.430990: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed1e00 of size 256 next 106\n",
      "2024-11-07 01:48:12.430996: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed1f00 of size 256 next 107\n",
      "2024-11-07 01:48:12.431001: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed2000 of size 256 next 110\n",
      "2024-11-07 01:48:12.431006: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed2100 of size 256 next 108\n",
      "2024-11-07 01:48:12.431011: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed2200 of size 256 next 109\n",
      "2024-11-07 01:48:12.431017: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed2300 of size 256 next 113\n",
      "2024-11-07 01:48:12.431022: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed2400 of size 256 next 114\n",
      "2024-11-07 01:48:12.431027: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed2500 of size 256 next 115\n",
      "2024-11-07 01:48:12.431032: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed2600 of size 256 next 118\n",
      "2024-11-07 01:48:12.431038: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed2700 of size 256 next 117\n",
      "2024-11-07 01:48:12.431043: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed2800 of size 256 next 119\n",
      "2024-11-07 01:48:12.431048: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed2900 of size 256 next 120\n",
      "2024-11-07 01:48:12.431053: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed2a00 of size 2048 next 121\n",
      "2024-11-07 01:48:12.431059: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed3200 of size 2048 next 123\n",
      "2024-11-07 01:48:12.431064: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed3a00 of size 256 next 126\n",
      "2024-11-07 01:48:12.431069: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed3b00 of size 256 next 125\n",
      "2024-11-07 01:48:12.431074: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed3c00 of size 256 next 127\n",
      "2024-11-07 01:48:12.431079: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed3d00 of size 256 next 128\n",
      "2024-11-07 01:48:12.431084: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed3e00 of size 2048 next 131\n",
      "2024-11-07 01:48:12.431090: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed4600 of size 2048 next 129\n",
      "2024-11-07 01:48:12.431095: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed4e00 of size 2816 next 22\n",
      "2024-11-07 01:48:12.431101: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ed5900 of size 73728 next 23\n",
      "2024-11-07 01:48:12.431106: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ee7900 of size 2048 next 152\n",
      "2024-11-07 01:48:12.431111: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ee8100 of size 2048 next 153\n",
      "2024-11-07 01:48:12.431116: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ee8900 of size 2048 next 154\n",
      "2024-11-07 01:48:12.431121: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ee9100 of size 2048 next 155\n",
      "2024-11-07 01:48:12.431126: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ee9900 of size 2048 next 157\n",
      "2024-11-07 01:48:12.431132: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eea100 of size 2048 next 158\n",
      "2024-11-07 01:48:12.431137: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eea900 of size 2048 next 159\n",
      "2024-11-07 01:48:12.431142: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eeb100 of size 2048 next 160\n",
      "2024-11-07 01:48:12.431147: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eeb900 of size 2048 next 161\n",
      "2024-11-07 01:48:12.431152: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eec100 of size 2048 next 163\n",
      "2024-11-07 01:48:12.431157: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eec900 of size 2048 next 164\n",
      "2024-11-07 01:48:12.431163: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eed100 of size 2048 next 165\n",
      "2024-11-07 01:48:12.431186: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eed900 of size 256 next 166\n",
      "2024-11-07 01:48:12.431194: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eeda00 of size 256 next 167\n",
      "2024-11-07 01:48:12.431199: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eedb00 of size 256 next 169\n",
      "2024-11-07 01:48:12.431207: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eedc00 of size 256 next 170\n",
      "2024-11-07 01:48:12.431213: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eedd00 of size 256 next 168\n",
      "2024-11-07 01:48:12.431218: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eede00 of size 256 next 174\n",
      "2024-11-07 01:48:12.431223: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eedf00 of size 256 next 173\n",
      "2024-11-07 01:48:12.431228: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eee000 of size 256 next 175\n",
      "2024-11-07 01:48:12.431233: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eee100 of size 256 next 171\n",
      "2024-11-07 01:48:12.431238: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eee200 of size 2048 next 178\n",
      "2024-11-07 01:48:12.431243: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eeea00 of size 1024 next 179\n",
      "2024-11-07 01:48:12.431248: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eeee00 of size 2048 next 177\n",
      "2024-11-07 01:48:12.431253: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eef600 of size 256 next 183\n",
      "2024-11-07 01:48:12.431258: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eef700 of size 2048 next 180\n",
      "2024-11-07 01:48:12.431263: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203eeff00 of size 256 next 186\n",
      "2024-11-07 01:48:12.431269: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef0000 of size 256 next 192\n",
      "2024-11-07 01:48:12.431274: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef0100 of size 256 next 187\n",
      "2024-11-07 01:48:12.431279: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef0200 of size 256 next 188\n",
      "2024-11-07 01:48:12.431284: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef0300 of size 2048 next 182\n",
      "2024-11-07 01:48:12.431289: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef0b00 of size 2048 next 189\n",
      "2024-11-07 01:48:12.431294: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef1300 of size 2048 next 190\n",
      "2024-11-07 01:48:12.431300: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef1b00 of size 2048 next 191\n",
      "2024-11-07 01:48:12.431305: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef2300 of size 256 next 194\n",
      "2024-11-07 01:48:12.431310: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef2400 of size 256 next 228\n",
      "2024-11-07 01:48:12.431315: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef2500 of size 256 next 195\n",
      "2024-11-07 01:48:12.431320: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef2600 of size 256 next 196\n",
      "2024-11-07 01:48:12.431325: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef2700 of size 2048 next 193\n",
      "2024-11-07 01:48:12.431330: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef2f00 of size 2048 next 198\n",
      "2024-11-07 01:48:12.431335: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef3700 of size 2048 next 199\n",
      "2024-11-07 01:48:12.431340: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef3f00 of size 2048 next 200\n",
      "2024-11-07 01:48:12.431345: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef4700 of size 2048 next 201\n",
      "2024-11-07 01:48:12.431350: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef4f00 of size 2048 next 202\n",
      "2024-11-07 01:48:12.431356: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef5700 of size 2048 next 204\n",
      "2024-11-07 01:48:12.431361: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef5f00 of size 2048 next 205\n",
      "2024-11-07 01:48:12.431366: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef6700 of size 2048 next 206\n",
      "2024-11-07 01:48:12.431371: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef6f00 of size 2048 next 207\n",
      "2024-11-07 01:48:12.431376: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef7700 of size 2048 next 208\n",
      "2024-11-07 01:48:12.431383: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef7f00 of size 2048 next 210\n",
      "2024-11-07 01:48:12.431388: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef8700 of size 2048 next 211\n",
      "2024-11-07 01:48:12.431393: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef8f00 of size 2048 next 212\n",
      "2024-11-07 01:48:12.431398: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef9700 of size 2048 next 213\n",
      "2024-11-07 01:48:12.431403: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203ef9f00 of size 2048 next 214\n",
      "2024-11-07 01:48:12.431409: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203efa700 of size 2048 next 216\n",
      "2024-11-07 01:48:12.431414: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203efaf00 of size 2048 next 217\n",
      "2024-11-07 01:48:12.431419: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203efb700 of size 2048 next 218\n",
      "2024-11-07 01:48:12.431424: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203efbf00 of size 2048 next 219\n",
      "2024-11-07 01:48:12.431429: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203efc700 of size 2048 next 220\n",
      "2024-11-07 01:48:12.431434: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203efcf00 of size 3840 next 172\n",
      "2024-11-07 01:48:12.431440: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203efde00 of size 39680 next 70\n",
      "2024-11-07 01:48:12.431446: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f07900 of size 131072 next 68\n",
      "2024-11-07 01:48:12.431452: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f27900 of size 131072 next 67\n",
      "2024-11-07 01:48:12.431458: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f47900 of size 2048 next 222\n",
      "2024-11-07 01:48:12.431464: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f48100 of size 2048 next 223\n",
      "2024-11-07 01:48:12.431469: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f48900 of size 2048 next 224\n",
      "2024-11-07 01:48:12.431475: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f49100 of size 1024 next 226\n",
      "2024-11-07 01:48:12.431482: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f49500 of size 256 next 225\n",
      "2024-11-07 01:48:12.431487: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f49600 of size 256 next 229\n",
      "2024-11-07 01:48:12.431492: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f49700 of size 1024 next 235\n",
      "2024-11-07 01:48:12.431498: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f49b00 of size 256 next 234\n",
      "2024-11-07 01:48:12.431504: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f49c00 of size 1024 next 237\n",
      "2024-11-07 01:48:12.431509: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4a000 of size 1536 next 239\n",
      "2024-11-07 01:48:12.431516: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4a600 of size 1024 next 240\n",
      "2024-11-07 01:48:12.431521: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4aa00 of size 1024 next 231\n",
      "2024-11-07 01:48:12.431527: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4ae00 of size 1024 next 238\n",
      "2024-11-07 01:48:12.431533: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4b200 of size 256 next 241\n",
      "2024-11-07 01:48:12.431539: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4b300 of size 256 next 243\n",
      "2024-11-07 01:48:12.431544: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4b400 of size 1024 next 245\n",
      "2024-11-07 01:48:12.431550: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4b800 of size 256 next 244\n",
      "2024-11-07 01:48:12.431555: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4b900 of size 1280 next 246\n",
      "2024-11-07 01:48:12.431561: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4be00 of size 1024 next 247\n",
      "2024-11-07 01:48:12.431566: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4c200 of size 1024 next 242\n",
      "2024-11-07 01:48:12.431572: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4c600 of size 1024 next 250\n",
      "2024-11-07 01:48:12.431577: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4ca00 of size 1024 next 251\n",
      "2024-11-07 01:48:12.431583: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4ce00 of size 256 next 253\n",
      "2024-11-07 01:48:12.431589: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4cf00 of size 256 next 254\n",
      "2024-11-07 01:48:12.431594: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4d000 of size 256 next 252\n",
      "2024-11-07 01:48:12.431599: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4d100 of size 256 next 259\n",
      "2024-11-07 01:48:12.431605: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4d200 of size 1792 next 256\n",
      "2024-11-07 01:48:12.431610: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4d900 of size 1024 next 257\n",
      "2024-11-07 01:48:12.431615: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4dd00 of size 1024 next 261\n",
      "2024-11-07 01:48:12.431621: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4e100 of size 1024 next 255\n",
      "2024-11-07 01:48:12.431626: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4e500 of size 1024 next 258\n",
      "2024-11-07 01:48:12.431631: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4e900 of size 1024 next 263\n",
      "2024-11-07 01:48:12.431636: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4ed00 of size 1024 next 266\n",
      "2024-11-07 01:48:12.431641: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4f100 of size 1024 next 264\n",
      "2024-11-07 01:48:12.431646: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4f500 of size 1024 next 265\n",
      "2024-11-07 01:48:12.431652: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4f900 of size 1024 next 268\n",
      "2024-11-07 01:48:12.431657: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f4fd00 of size 1024 next 269\n",
      "2024-11-07 01:48:12.431662: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f50100 of size 1024 next 270\n",
      "2024-11-07 01:48:12.431667: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f50500 of size 1024 next 271\n",
      "2024-11-07 01:48:12.431672: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f50900 of size 1024 next 272\n",
      "2024-11-07 01:48:12.431677: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f50d00 of size 1024 next 274\n",
      "2024-11-07 01:48:12.431682: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f51100 of size 1024 next 275\n",
      "2024-11-07 01:48:12.431688: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f51500 of size 1024 next 276\n",
      "2024-11-07 01:48:12.431693: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f51900 of size 1024 next 277\n",
      "2024-11-07 01:48:12.431698: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f51d00 of size 1024 next 279\n",
      "2024-11-07 01:48:12.431703: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f52100 of size 1024 next 280\n",
      "2024-11-07 01:48:12.431708: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f52500 of size 1024 next 281\n",
      "2024-11-07 01:48:12.431714: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 203f52900 of size 27904 next 230\n",
      "2024-11-07 01:48:12.431719: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f59600 of size 58112 next 176\n",
      "2024-11-07 01:48:12.431725: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f67900 of size 65536 next 32\n",
      "2024-11-07 01:48:12.431731: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203f77900 of size 294912 next 31\n",
      "2024-11-07 01:48:12.431737: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203fbf900 of size 131072 next 71\n",
      "2024-11-07 01:48:12.431742: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203fdf900 of size 65536 next 184\n",
      "2024-11-07 01:48:12.431747: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 203fef900 of size 393216 next 52\n",
      "2024-11-07 01:48:12.431753: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20404f900 of size 589824 next 51\n",
      "2024-11-07 01:48:12.431759: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2040df900 of size 262144 next 249\n",
      "2024-11-07 01:48:12.431765: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 20411f900 of size 262144 next 288\n",
      "2024-11-07 01:48:12.431770: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20415f900 of size 262144 next 287\n",
      "2024-11-07 01:48:12.431775: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 20419f900 of size 262144 next 77\n",
      "2024-11-07 01:48:12.431781: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2041df900 of size 524288 next 76\n",
      "2024-11-07 01:48:12.431787: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20425f900 of size 524288 next 122\n",
      "2024-11-07 01:48:12.431793: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2042df900 of size 524288 next 124\n",
      "2024-11-07 01:48:12.431798: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20435f900 of size 524288 next 227\n",
      "2024-11-07 01:48:12.431803: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043df900 of size 16384 next 260\n",
      "2024-11-07 01:48:12.431809: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e3900 of size 256 next 283\n",
      "2024-11-07 01:48:12.431814: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e3a00 of size 256 next 282\n",
      "2024-11-07 01:48:12.431819: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e3b00 of size 256 next 289\n",
      "2024-11-07 01:48:12.431825: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e3c00 of size 256 next 290\n",
      "2024-11-07 01:48:12.431830: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e3d00 of size 256 next 299\n",
      "2024-11-07 01:48:12.431835: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e3e00 of size 256 next 302\n",
      "2024-11-07 01:48:12.431840: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e3f00 of size 256 next 301\n",
      "2024-11-07 01:48:12.431846: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e4000 of size 256 next 303\n",
      "2024-11-07 01:48:12.431851: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e4100 of size 256 next 300\n",
      "2024-11-07 01:48:12.431856: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e4200 of size 1024 next 292\n",
      "2024-11-07 01:48:12.431861: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e4600 of size 1024 next 293\n",
      "2024-11-07 01:48:12.431866: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e4a00 of size 256 next 291\n",
      "2024-11-07 01:48:12.431872: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e4b00 of size 256 next 284\n",
      "2024-11-07 01:48:12.431877: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e4c00 of size 256 next 298\n",
      "2024-11-07 01:48:12.431882: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e4d00 of size 256 next 294\n",
      "2024-11-07 01:48:12.431887: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e4e00 of size 256 next 295\n",
      "2024-11-07 01:48:12.431893: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e4f00 of size 1024 next 296\n",
      "2024-11-07 01:48:12.431898: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e5300 of size 256 next 304\n",
      "2024-11-07 01:48:12.431903: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e5400 of size 256 next 305\n",
      "2024-11-07 01:48:12.431908: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e5500 of size 256 next 306\n",
      "2024-11-07 01:48:12.431914: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e5600 of size 256 next 307\n",
      "2024-11-07 01:48:12.431919: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e5700 of size 256 next 308\n",
      "2024-11-07 01:48:12.431924: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e5800 of size 256 next 309\n",
      "2024-11-07 01:48:12.431929: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e5900 of size 256 next 310\n",
      "2024-11-07 01:48:12.431935: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e5a00 of size 256 next 311\n",
      "2024-11-07 01:48:12.431940: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e5b00 of size 256 next 312\n",
      "2024-11-07 01:48:12.431945: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e5c00 of size 256 next 313\n",
      "2024-11-07 01:48:12.431950: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e5d00 of size 256 next 314\n",
      "2024-11-07 01:48:12.431955: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e5e00 of size 256 next 315\n",
      "2024-11-07 01:48:12.431961: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e5f00 of size 256 next 319\n",
      "2024-11-07 01:48:12.431966: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e6000 of size 256 next 320\n",
      "2024-11-07 01:48:12.431971: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e6100 of size 256 next 321\n",
      "2024-11-07 01:48:12.431976: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e6200 of size 256 next 322\n",
      "2024-11-07 01:48:12.431981: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e6300 of size 256 next 325\n",
      "2024-11-07 01:48:12.431986: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e6400 of size 256 next 326\n",
      "2024-11-07 01:48:12.431991: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e6500 of size 256 next 327\n",
      "2024-11-07 01:48:12.431997: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e6600 of size 256 next 328\n",
      "2024-11-07 01:48:12.432002: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 2043e6700 of size 4864 next 285\n",
      "2024-11-07 01:48:12.432007: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2043e7a00 of size 16384 next 286\n",
      "2024-11-07 01:48:12.432013: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 2043eba00 of size 212736 next 233\n",
      "2024-11-07 01:48:12.432018: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20441f900 of size 262144 next 232\n",
      "2024-11-07 01:48:12.432023: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20445f900 of size 262144 next 82\n",
      "2024-11-07 01:48:12.432029: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20449f900 of size 1179648 next 81\n",
      "2024-11-07 01:48:12.432034: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2045bf900 of size 1048576 next 181\n",
      "2024-11-07 01:48:12.432040: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2046bf900 of size 1310720 next 90\n",
      "2024-11-07 01:48:12.432046: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2047ff900 of size 2359296 next 89\n",
      "2024-11-07 01:48:12.432052: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 204a3f900 of size 2359296 next 96\n",
      "2024-11-07 01:48:12.432057: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 204c7f900 of size 2359296 next 102\n",
      "2024-11-07 01:48:12.432063: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 204ebf900 of size 2359296 next 248\n",
      "2024-11-07 01:48:12.432068: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2050ff900 of size 2359296 next 262\n",
      "2024-11-07 01:48:12.432073: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20533f900 of size 262144 next 297\n",
      "2024-11-07 01:48:12.432078: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 20537f900 of size 2097152 next 273\n",
      "2024-11-07 01:48:12.432084: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20557f900 of size 2359296 next 133\n",
      "2024-11-07 01:48:12.432089: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2057bf900 of size 4718592 next 132\n",
      "2024-11-07 01:48:12.432096: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 205c3f900 of size 4718592 next 236\n",
      "2024-11-07 01:48:12.432101: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 2060bf900 of size 2359296 next 267\n",
      "2024-11-07 01:48:12.432106: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 2062ff900 of size 2359296 next 140\n",
      "2024-11-07 01:48:12.432112: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20653f900 of size 9437184 next 139\n",
      "2024-11-07 01:48:12.432117: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 206e3f900 of size 9437184 next 145\n",
      "2024-11-07 01:48:12.432123: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20773f900 of size 9437184 next 151\n",
      "2024-11-07 01:48:12.432128: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20803f900 of size 9437184 next 156\n",
      "2024-11-07 01:48:12.432133: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20893f900 of size 9437184 next 162\n",
      "2024-11-07 01:48:12.432139: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20923f900 of size 9437184 next 185\n",
      "2024-11-07 01:48:12.432144: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 209b3f900 of size 9437184 next 197\n",
      "2024-11-07 01:48:12.432149: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20a43f900 of size 9437184 next 203\n",
      "2024-11-07 01:48:12.432155: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20ad3f900 of size 9437184 next 209\n",
      "2024-11-07 01:48:12.432160: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20b63f900 of size 9437184 next 215\n",
      "2024-11-07 01:48:12.432165: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20bf3f900 of size 9437184 next 221\n",
      "2024-11-07 01:48:12.432170: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20c83f900 of size 2359296 next 278\n",
      "2024-11-07 01:48:12.432176: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 20ca7f900 of size 67239936 next 316\n",
      "2024-11-07 01:48:12.432182: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 210a9f900 of size 179306496 next 317\n",
      "2024-11-07 01:48:12.432188: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 21b59f900 of size 179306496 next 318\n",
      "2024-11-07 01:48:12.432193: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 22609f900 of size 358612992 next 323\n",
      "2024-11-07 01:48:12.432199: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 23b69f900 of size 358612992 next 324\n",
      "2024-11-07 01:48:12.432204: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 250c9f900 of size 358612992 next 329\n",
      "2024-11-07 01:48:12.432209: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] InUse at 26629f900 of size 717225984 next 330\n",
      "2024-11-07 01:48:12.432215: I external/local_tsl/tsl/framework/bfc_allocator.cc:1095] Free  at 290e9f900 of size 223659776 next 18446744073709551615\n",
      "2024-11-07 01:48:12.432220: I external/local_tsl/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2024-11-07 01:48:12.432229: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 127 Chunks of size 256 totalling 31.8KiB\n",
      "2024-11-07 01:48:12.432236: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 12 Chunks of size 512 totalling 6.0KiB\n",
      "2024-11-07 01:48:12.432242: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 58 Chunks of size 1024 totalling 58.0KiB\n",
      "2024-11-07 01:48:12.432248: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 1280 totalling 2.5KiB\n",
      "2024-11-07 01:48:12.432253: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1536 totalling 1.5KiB\n",
      "2024-11-07 01:48:12.432259: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1792 totalling 1.8KiB\n",
      "2024-11-07 01:48:12.432265: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 62 Chunks of size 2048 totalling 124.0KiB\n",
      "2024-11-07 01:48:12.432271: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 2816 totalling 2.8KiB\n",
      "2024-11-07 01:48:12.432276: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 3584 totalling 7.0KiB\n",
      "2024-11-07 01:48:12.432282: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3840 totalling 3.8KiB\n",
      "2024-11-07 01:48:12.432288: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 16384 totalling 64.0KiB\n",
      "2024-11-07 01:48:12.432294: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 32768 totalling 32.0KiB\n",
      "2024-11-07 01:48:12.432300: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 39680 totalling 38.8KiB\n",
      "2024-11-07 01:48:12.432306: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 58112 totalling 56.8KiB\n",
      "2024-11-07 01:48:12.432312: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 65536 totalling 128.0KiB\n",
      "2024-11-07 01:48:12.432317: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 73728 totalling 72.0KiB\n",
      "2024-11-07 01:48:12.432323: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 131072 totalling 384.0KiB\n",
      "2024-11-07 01:48:12.432329: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 5 Chunks of size 262144 totalling 1.25MiB\n",
      "2024-11-07 01:48:12.432335: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 294912 totalling 288.0KiB\n",
      "2024-11-07 01:48:12.432341: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 393216 totalling 384.0KiB\n",
      "2024-11-07 01:48:12.432346: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 524288 totalling 2.00MiB\n",
      "2024-11-07 01:48:12.432352: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 589824 totalling 576.0KiB\n",
      "2024-11-07 01:48:12.432358: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1048576 totalling 1.00MiB\n",
      "2024-11-07 01:48:12.432363: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1179648 totalling 1.12MiB\n",
      "2024-11-07 01:48:12.432369: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1310720 totalling 1.25MiB\n",
      "2024-11-07 01:48:12.432375: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 8 Chunks of size 2359296 totalling 18.00MiB\n",
      "2024-11-07 01:48:12.432381: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 4718592 totalling 9.00MiB\n",
      "2024-11-07 01:48:12.432387: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 11 Chunks of size 9437184 totalling 99.00MiB\n",
      "2024-11-07 01:48:12.432392: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 67239936 totalling 64.12MiB\n",
      "2024-11-07 01:48:12.432398: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 179306496 totalling 342.00MiB\n",
      "2024-11-07 01:48:12.432404: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 358612992 totalling 684.00MiB\n",
      "2024-11-07 01:48:12.432410: I external/local_tsl/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 717225984 totalling 684.00MiB\n",
      "2024-11-07 01:48:12.432416: I external/local_tsl/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 1.86GiB\n",
      "2024-11-07 01:48:12.432423: I external/local_tsl/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 2589188096 memory_limit_: 2589188096 available bytes: 0 curr_region_allocation_bytes_: 5178376192\n",
      "2024-11-07 01:48:12.432434: I external/local_tsl/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                      2589188096\n",
      "InUse:                      2001689088\n",
      "MaxInUse:                   2001984000\n",
      "NumAllocs:                         811\n",
      "MaxAllocSize:                717225984\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-11-07 01:48:12.432451: W external/local_tsl/tsl/framework/bfc_allocator.cc:497] ***********************____________*********************************************************________\n",
      "2024-11-07 01:48:12.432490: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at bias_op.cc:273 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[12,256,456,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer 'conv2d_2' (type Conv2D).\n\n{{function_node __wrapped__BiasAdd_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[12,256,456,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:BiasAdd] name: \n\nCall arguments received by layer 'conv2d_2' (type Conv2D):\n  • inputs=tf.Tensor(shape=(12, 256, 456, 64), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdexined_try\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 49\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, model_name, train_data, test_data, lr, beta1, max_epochs, batch_size)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_data):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 49\u001b[0m         pred \u001b[38;5;241m=\u001b[39m \u001b[43mmy_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m         preds, loss \u001b[38;5;241m=\u001b[39m pre_process_binary_cross_entropy(\n\u001b[1;32m     52\u001b[0m             loss_bc, pred, y, use_tf_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m     accuracy\u001b[38;5;241m.\u001b[39mupdate_state(y_true\u001b[38;5;241m=\u001b[39my, y_pred\u001b[38;5;241m=\u001b[39mpreds[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py:5883\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   5882\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 5883\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer 'conv2d_2' (type Conv2D).\n\n{{function_node __wrapped__BiasAdd_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[12,256,456,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:BiasAdd] name: \n\nCall arguments received by layer 'conv2d_2' (type Conv2D):\n  • inputs=tf.Tensor(shape=(12, 256, 456, 64), dtype=float32)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Step: 270 Loss: 0.3419 Accuracy: 0.6348 Tue Nov  5 01:33:13 2024\n",
      "Epoch: 6 Step: 280 Loss: 0.3389 Accuracy: 0.6348 Tue Nov  5 01:33:17 2024\n",
      "Epoch: 6 Step: 290 Loss: 0.3406 Accuracy: 0.6348 Tue Nov  5 01:33:20 2024\n",
      "Epoch: 6 Step: 300 Loss: 0.3388 Accuracy: 0.6348 Tue Nov  5 01:33:24 2024\n",
      "Epoch: 6 Step: 310 Loss: 0.3431 Accuracy: 0.6348 Tue Nov  5 01:33:27 2024\n",
      "Epoch: 6 Step: 320 Loss: 0.3364 Accuracy: 0.6349 Tue Nov  5 01:33:31 2024\n",
      "Epoch: 6 Step: 330 Loss: 0.3405 Accuracy: 0.6349 Tue Nov  5 01:33:35 2024\n",
      "Epoch: 6 Step: 340 Loss: 0.3395 Accuracy: 0.6348 Tue Nov  5 01:33:38 2024\n",
      "Epoch: 6 Step: 350 Loss: 0.3388 Accuracy: 0.6349 Tue Nov  5 01:33:42 2024\n",
      "Epoch: 6 Step: 360 Loss: 0.3393 Accuracy: 0.6349 Tue Nov  5 01:33:45 2024\n",
      "Epoch: 6 Step: 370 Loss: 0.3401 Accuracy: 0.6348 Tue Nov  5 01:33:49 2024\n",
      "Epoch: 6 Step: 380 Loss: 0.3412 Accuracy: 0.6348 Tue Nov  5 01:33:53 2024\n",
      "Epoch: 6 Step: 390 Loss: 0.3392 Accuracy: 0.6348 Tue Nov  5 01:33:56 2024\n",
      "Epoch: 6 Step: 400 Loss: 0.3395 Accuracy: 0.6348 Tue Nov  5 01:34:00 2024\n",
      "Epoch: 6 Step: 410 Loss: 0.3407 Accuracy: 0.6348 Tue Nov  5 01:34:03 2024\n",
      "Epoch: 6 Step: 420 Loss: 0.3406 Accuracy: 0.6348 Tue Nov  5 01:34:07 2024\n",
      "Epoch: 6 Step: 430 Loss: 0.3406 Accuracy: 0.6348 Tue Nov  5 01:34:11 2024\n",
      "Epoch: 6 Step: 440 Loss: 0.3391 Accuracy: 0.6349 Tue Nov  5 01:34:14 2024\n",
      "Epoch: 6 Step: 450 Loss: 0.3388 Accuracy: 0.6348 Tue Nov  5 01:34:18 2024\n",
      "Epoch: 6 Step: 460 Loss: 0.3405 Accuracy: 0.6348 Tue Nov  5 01:34:21 2024\n",
      "Epoch: 6 Step: 470 Loss: 0.3417 Accuracy: 0.6348 Tue Nov  5 01:34:25 2024\n",
      "Epoch: 6 Step: 480 Loss: 0.3405 Accuracy: 0.6348 Tue Nov  5 01:34:29 2024\n",
      "Epoch: 6 Step: 490 Loss: 0.3413 Accuracy: 0.6348 Tue Nov  5 01:34:32 2024\n",
      "Epoch: 6 Step: 500 Loss: 0.3412 Accuracy: 0.6348 Tue Nov  5 01:34:36 2024\n",
      "Epoch: 6 Step: 510 Loss: 0.3420 Accuracy: 0.6347 Tue Nov  5 01:34:39 2024\n",
      "Epoch: 6 Step: 520 Loss: 0.3391 Accuracy: 0.6347 Tue Nov  5 01:34:43 2024\n",
      "Epoch: 6 Step: 530 Loss: 0.3417 Accuracy: 0.6347 Tue Nov  5 01:34:47 2024\n",
      "Epoch: 6 Step: 540 Loss: 0.3403 Accuracy: 0.6347 Tue Nov  5 01:34:50 2024\n",
      "Epoch: 6 Step: 550 Loss: 0.3421 Accuracy: 0.6347 Tue Nov  5 01:34:54 2024\n",
      "Epoch: 6 Step: 560 Loss: 0.3396 Accuracy: 0.6347 Tue Nov  5 01:34:57 2024\n",
      "Epoch: 6 Step: 570 Loss: 0.3414 Accuracy: 0.6347 Tue Nov  5 01:35:01 2024\n",
      "Epoch: 6 Step: 580 Loss: 0.3398 Accuracy: 0.6347 Tue Nov  5 01:35:05 2024\n",
      "Epoch: 6 Step: 590 Loss: 0.3410 Accuracy: 0.6347 Tue Nov  5 01:35:08 2024\n",
      "Epoch: 6 Step: 600 Loss: 0.3372 Accuracy: 0.6347 Tue Nov  5 01:35:12 2024\n",
      "Epoch: 6 Step: 610 Loss: 0.3404 Accuracy: 0.6347 Tue Nov  5 01:35:15 2024\n",
      "Epoch: 6 Step: 620 Loss: 0.3417 Accuracy: 0.6347 Tue Nov  5 01:35:19 2024\n",
      "Epoch: 6 Step: 630 Loss: 0.3391 Accuracy: 0.6348 Tue Nov  5 01:35:23 2024\n",
      "Epoch: 6 Step: 640 Loss: 0.3387 Accuracy: 0.6348 Tue Nov  5 01:35:26 2024\n",
      "Epoch: 6 Step: 650 Loss: 0.3369 Accuracy: 0.6348 Tue Nov  5 01:35:30 2024\n",
      "Epoch: 6 Step: 660 Loss: 0.3398 Accuracy: 0.6348 Tue Nov  5 01:35:33 2024\n",
      "Epoch: 6 Step: 670 Loss: 0.3432 Accuracy: 0.6348 Tue Nov  5 01:35:37 2024\n",
      "Epoch: 6 Step: 680 Loss: 0.3415 Accuracy: 0.6348 Tue Nov  5 01:35:41 2024\n",
      "Epoch: 6 Step: 690 Loss: 0.3406 Accuracy: 0.6349 Tue Nov  5 01:35:44 2024\n",
      "Epoch: 6 Step: 700 Loss: 0.3436 Accuracy: 0.6348 Tue Nov  5 01:35:48 2024\n",
      "Epoch: 6 Step: 710 Loss: 0.3405 Accuracy: 0.6348 Tue Nov  5 01:35:51 2024\n",
      "Epoch: 6 Step: 720 Loss: 0.3389 Accuracy: 0.6348 Tue Nov  5 01:35:55 2024\n",
      "Epoch: 6 Step: 730 Loss: 0.3379 Accuracy: 0.6348 Tue Nov  5 01:35:59 2024\n",
      "Epoch: 6 Step: 740 Loss: 0.3384 Accuracy: 0.6349 Tue Nov  5 01:36:02 2024\n",
      "Epoch: 6 Step: 750 Loss: 0.3412 Accuracy: 0.6348 Tue Nov  5 01:36:06 2024\n",
      "Epoch: 6 Step: 760 Loss: 0.3419 Accuracy: 0.6349 Tue Nov  5 01:36:09 2024\n",
      "Epoch: 6 Step: 770 Loss: 0.3412 Accuracy: 0.6349 Tue Nov  5 01:36:13 2024\n",
      "Epoch: 6 Step: 780 Loss: 0.3421 Accuracy: 0.6349 Tue Nov  5 01:36:17 2024\n",
      "Epoch: 6 Step: 790 Loss: 0.3422 Accuracy: 0.6349 Tue Nov  5 01:36:20 2024\n",
      "Epoch: 6 Step: 800 Loss: 0.3420 Accuracy: 0.6348 Tue Nov  5 01:36:24 2024\n",
      "Epoch: 6 Step: 810 Loss: 0.3415 Accuracy: 0.6348 Tue Nov  5 01:36:27 2024\n",
      "Epoch: 6 Step: 820 Loss: 0.3398 Accuracy: 0.6348 Tue Nov  5 01:36:31 2024\n",
      "Epoch: 6 Step: 830 Loss: 0.3406 Accuracy: 0.6348 Tue Nov  5 01:36:35 2024\n",
      "Epoch: 6 Step: 840 Loss: 0.3404 Accuracy: 0.6348 Tue Nov  5 01:36:38 2024\n",
      "Epoch: 6 Step: 850 Loss: 0.3397 Accuracy: 0.6349 Tue Nov  5 01:36:42 2024\n",
      "Epoch: 6 Step: 860 Loss: 0.3398 Accuracy: 0.6349 Tue Nov  5 01:36:45 2024\n",
      "Epoch: 6 Step: 870 Loss: 0.3401 Accuracy: 0.6349 Tue Nov  5 01:36:49 2024\n",
      "Epoch: 6 Step: 880 Loss: 0.3425 Accuracy: 0.6349 Tue Nov  5 01:36:53 2024\n",
      "Epoch: 6 Step: 890 Loss: 0.3410 Accuracy: 0.6349 Tue Nov  5 01:36:56 2024\n",
      "Epoch: 6 Step: 900 Loss: 0.3405 Accuracy: 0.6349 Tue Nov  5 01:37:00 2024\n",
      "Epoch: 6 Step: 910 Loss: 0.3424 Accuracy: 0.6349 Tue Nov  5 01:37:04 2024\n",
      "Epoch: 6 Step: 920 Loss: 0.3377 Accuracy: 0.6349 Tue Nov  5 01:37:07 2024\n",
      "Epoch: 6 Step: 930 Loss: 0.3406 Accuracy: 0.6349 Tue Nov  5 01:37:11 2024\n",
      "Epoch: 6 Step: 940 Loss: 0.3413 Accuracy: 0.6349 Tue Nov  5 01:37:14 2024\n",
      "Epoch: 6 Step: 950 Loss: 0.3412 Accuracy: 0.6349 Tue Nov  5 01:37:18 2024\n",
      "Epoch: 6 Step: 960 Loss: 0.3384 Accuracy: 0.6350 Tue Nov  5 01:37:22 2024\n",
      "Epoch: 6 Step: 970 Loss: 0.3396 Accuracy: 0.6350 Tue Nov  5 01:37:25 2024\n",
      "Epoch: 6 Step: 980 Loss: 0.3404 Accuracy: 0.6349 Tue Nov  5 01:37:29 2024\n",
      "Epoch: 6 Step: 990 Loss: 0.3421 Accuracy: 0.6349 Tue Nov  5 01:37:32 2024\n",
      "Epoch: 6 Step: 1000 Loss: 0.3385 Accuracy: 0.6349 Tue Nov  5 01:37:36 2024\n",
      "Epoch: 6 Step: 1010 Loss: 0.3427 Accuracy: 0.6349 Tue Nov  5 01:37:40 2024\n",
      "Epoch: 6 Step: 1020 Loss: 0.3396 Accuracy: 0.6349 Tue Nov  5 01:37:43 2024\n",
      "Epoch: 6 Step: 1030 Loss: 0.3420 Accuracy: 0.6349 Tue Nov  5 01:37:47 2024\n",
      "Epoch: 6 Model saved in Loss:  0.34031644\n",
      "Epoch(validation): 6 Val loss:  0.34069037 Accuracy:  0.63401717\n",
      "Epoch: 7 Step: 0 Loss: 0.3401 Accuracy: 0.6355 Tue Nov  5 01:37:51 2024\n",
      "Epoch: 7 Step: 10 Loss: 0.3408 Accuracy: 0.6342 Tue Nov  5 01:37:55 2024\n",
      "Epoch: 7 Step: 20 Loss: 0.3425 Accuracy: 0.6344 Tue Nov  5 01:37:59 2024\n",
      "Epoch: 7 Step: 30 Loss: 0.3390 Accuracy: 0.6351 Tue Nov  5 01:38:02 2024\n",
      "Epoch: 7 Step: 40 Loss: 0.3412 Accuracy: 0.6352 Tue Nov  5 01:38:06 2024\n",
      "Epoch: 7 Step: 50 Loss: 0.3399 Accuracy: 0.6352 Tue Nov  5 01:38:10 2024\n",
      "Epoch: 7 Step: 60 Loss: 0.3403 Accuracy: 0.6350 Tue Nov  5 01:38:13 2024\n",
      "Epoch: 7 Step: 70 Loss: 0.3390 Accuracy: 0.6350 Tue Nov  5 01:38:17 2024\n",
      "Epoch: 7 Step: 80 Loss: 0.3392 Accuracy: 0.6349 Tue Nov  5 01:38:20 2024\n",
      "Epoch: 7 Step: 90 Loss: 0.3387 Accuracy: 0.6347 Tue Nov  5 01:38:24 2024\n",
      "Epoch: 7 Step: 100 Loss: 0.3400 Accuracy: 0.6348 Tue Nov  5 01:38:28 2024\n",
      "Epoch: 7 Step: 110 Loss: 0.3419 Accuracy: 0.6348 Tue Nov  5 01:38:31 2024\n",
      "Epoch: 7 Step: 120 Loss: 0.3408 Accuracy: 0.6349 Tue Nov  5 01:38:35 2024\n",
      "Epoch: 7 Step: 130 Loss: 0.3429 Accuracy: 0.6349 Tue Nov  5 01:38:39 2024\n",
      "Epoch: 7 Step: 140 Loss: 0.3404 Accuracy: 0.6348 Tue Nov  5 01:38:42 2024\n",
      "Epoch: 7 Step: 150 Loss: 0.3392 Accuracy: 0.6347 Tue Nov  5 01:38:46 2024\n",
      "Epoch: 7 Step: 160 Loss: 0.3379 Accuracy: 0.6348 Tue Nov  5 01:38:50 2024\n",
      "Epoch: 7 Step: 170 Loss: 0.3400 Accuracy: 0.6348 Tue Nov  5 01:38:53 2024\n",
      "Epoch: 7 Step: 180 Loss: 0.3405 Accuracy: 0.6348 Tue Nov  5 01:38:57 2024\n",
      "Epoch: 7 Step: 190 Loss: 0.3408 Accuracy: 0.6348 Tue Nov  5 01:39:01 2024\n",
      "Epoch: 7 Step: 200 Loss: 0.3397 Accuracy: 0.6349 Tue Nov  5 01:39:04 2024\n",
      "Epoch: 7 Step: 210 Loss: 0.3401 Accuracy: 0.6348 Tue Nov  5 01:39:08 2024\n",
      "Epoch: 7 Step: 220 Loss: 0.3402 Accuracy: 0.6348 Tue Nov  5 01:39:11 2024\n",
      "Epoch: 7 Step: 230 Loss: 0.3416 Accuracy: 0.6347 Tue Nov  5 01:39:15 2024\n",
      "Epoch: 7 Step: 240 Loss: 0.3381 Accuracy: 0.6348 Tue Nov  5 01:39:19 2024\n",
      "Epoch: 7 Step: 250 Loss: 0.3381 Accuracy: 0.6349 Tue Nov  5 01:39:22 2024\n",
      "Epoch: 7 Step: 260 Loss: 0.3389 Accuracy: 0.6349 Tue Nov  5 01:39:26 2024\n",
      "Epoch: 7 Step: 270 Loss: 0.3405 Accuracy: 0.6349 Tue Nov  5 01:39:30 2024\n",
      "Epoch: 7 Step: 280 Loss: 0.3386 Accuracy: 0.6349 Tue Nov  5 01:39:33 2024\n",
      "Epoch: 7 Step: 290 Loss: 0.3439 Accuracy: 0.6349 Tue Nov  5 01:39:37 2024\n",
      "Epoch: 7 Step: 300 Loss: 0.3395 Accuracy: 0.6349 Tue Nov  5 01:39:40 2024\n",
      "Epoch: 7 Step: 310 Loss: 0.3411 Accuracy: 0.6348 Tue Nov  5 01:39:44 2024\n",
      "Epoch: 7 Step: 320 Loss: 0.3401 Accuracy: 0.6348 Tue Nov  5 01:39:48 2024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Step: 330 Loss: 0.3397 Accuracy: 0.6348 Tue Nov  5 01:39:52 2024\n",
      "Epoch: 7 Step: 340 Loss: 0.3406 Accuracy: 0.6348 Tue Nov  5 01:39:55 2024\n",
      "Epoch: 7 Step: 350 Loss: 0.3411 Accuracy: 0.6349 Tue Nov  5 01:39:59 2024\n",
      "Epoch: 7 Step: 360 Loss: 0.3406 Accuracy: 0.6349 Tue Nov  5 01:40:02 2024\n",
      "Epoch: 7 Step: 370 Loss: 0.3406 Accuracy: 0.6348 Tue Nov  5 01:40:06 2024\n",
      "Epoch: 7 Step: 380 Loss: 0.3422 Accuracy: 0.6348 Tue Nov  5 01:40:10 2024\n",
      "Epoch: 7 Step: 390 Loss: 0.3409 Accuracy: 0.6348 Tue Nov  5 01:40:13 2024\n",
      "Epoch: 7 Step: 400 Loss: 0.3412 Accuracy: 0.6348 Tue Nov  5 01:40:17 2024\n",
      "Epoch: 7 Step: 410 Loss: 0.3407 Accuracy: 0.6348 Tue Nov  5 01:40:21 2024\n",
      "Epoch: 7 Step: 420 Loss: 0.3417 Accuracy: 0.6348 Tue Nov  5 01:40:24 2024\n",
      "Epoch: 7 Step: 430 Loss: 0.3380 Accuracy: 0.6348 Tue Nov  5 01:40:28 2024\n",
      "Epoch: 7 Step: 440 Loss: 0.3393 Accuracy: 0.6348 Tue Nov  5 01:40:32 2024\n",
      "Epoch: 7 Step: 450 Loss: 0.3427 Accuracy: 0.6348 Tue Nov  5 01:40:35 2024\n",
      "Epoch: 7 Step: 460 Loss: 0.3405 Accuracy: 0.6348 Tue Nov  5 01:40:39 2024\n",
      "Epoch: 7 Step: 470 Loss: 0.3434 Accuracy: 0.6347 Tue Nov  5 01:40:43 2024\n",
      "Epoch: 7 Step: 480 Loss: 0.3407 Accuracy: 0.6347 Tue Nov  5 01:40:46 2024\n",
      "Epoch: 7 Step: 490 Loss: 0.3393 Accuracy: 0.6347 Tue Nov  5 01:40:50 2024\n",
      "Epoch: 7 Step: 500 Loss: 0.3372 Accuracy: 0.6348 Tue Nov  5 01:40:54 2024\n",
      "Epoch: 7 Step: 510 Loss: 0.3390 Accuracy: 0.6348 Tue Nov  5 01:40:57 2024\n",
      "Epoch: 7 Step: 520 Loss: 0.3405 Accuracy: 0.6348 Tue Nov  5 01:41:01 2024\n",
      "Epoch: 7 Step: 530 Loss: 0.3430 Accuracy: 0.6348 Tue Nov  5 01:41:04 2024\n",
      "Epoch: 7 Step: 540 Loss: 0.3388 Accuracy: 0.6348 Tue Nov  5 01:41:08 2024\n",
      "Epoch: 7 Step: 550 Loss: 0.3389 Accuracy: 0.6348 Tue Nov  5 01:41:12 2024\n",
      "Epoch: 7 Step: 560 Loss: 0.3426 Accuracy: 0.6348 Tue Nov  5 01:41:15 2024\n",
      "Epoch: 7 Step: 570 Loss: 0.3418 Accuracy: 0.6347 Tue Nov  5 01:41:19 2024\n",
      "Epoch: 7 Step: 580 Loss: 0.3432 Accuracy: 0.6347 Tue Nov  5 01:41:23 2024\n",
      "Epoch: 7 Step: 590 Loss: 0.3431 Accuracy: 0.6347 Tue Nov  5 01:41:26 2024\n",
      "Epoch: 7 Step: 600 Loss: 0.3420 Accuracy: 0.6347 Tue Nov  5 01:41:30 2024\n",
      "Epoch: 7 Step: 610 Loss: 0.3373 Accuracy: 0.6347 Tue Nov  5 01:41:34 2024\n",
      "Epoch: 7 Step: 620 Loss: 0.3402 Accuracy: 0.6348 Tue Nov  5 01:41:37 2024\n",
      "Epoch: 7 Step: 630 Loss: 0.3408 Accuracy: 0.6348 Tue Nov  5 01:41:41 2024\n",
      "Epoch: 7 Step: 640 Loss: 0.3389 Accuracy: 0.6348 Tue Nov  5 01:41:45 2024\n",
      "Epoch: 7 Step: 650 Loss: 0.3403 Accuracy: 0.6348 Tue Nov  5 01:41:48 2024\n",
      "Epoch: 7 Step: 660 Loss: 0.3418 Accuracy: 0.6348 Tue Nov  5 01:41:52 2024\n",
      "Epoch: 7 Step: 670 Loss: 0.3369 Accuracy: 0.6348 Tue Nov  5 01:41:55 2024\n",
      "Epoch: 7 Step: 680 Loss: 0.3394 Accuracy: 0.6348 Tue Nov  5 01:41:59 2024\n",
      "Epoch: 7 Step: 690 Loss: 0.3401 Accuracy: 0.6348 Tue Nov  5 01:42:03 2024\n",
      "Epoch: 7 Step: 700 Loss: 0.3406 Accuracy: 0.6348 Tue Nov  5 01:42:06 2024\n",
      "Epoch: 7 Step: 710 Loss: 0.3377 Accuracy: 0.6349 Tue Nov  5 01:42:10 2024\n",
      "Epoch: 7 Step: 720 Loss: 0.3412 Accuracy: 0.6349 Tue Nov  5 01:42:14 2024\n",
      "Epoch: 7 Step: 730 Loss: 0.3383 Accuracy: 0.6349 Tue Nov  5 01:42:17 2024\n",
      "Epoch: 7 Step: 740 Loss: 0.3410 Accuracy: 0.6349 Tue Nov  5 01:42:21 2024\n",
      "Epoch: 7 Step: 750 Loss: 0.3424 Accuracy: 0.6348 Tue Nov  5 01:42:25 2024\n",
      "Epoch: 7 Step: 760 Loss: 0.3415 Accuracy: 0.6349 Tue Nov  5 01:42:28 2024\n",
      "Epoch: 7 Step: 770 Loss: 0.3395 Accuracy: 0.6349 Tue Nov  5 01:42:32 2024\n",
      "Epoch: 7 Step: 780 Loss: 0.3367 Accuracy: 0.6348 Tue Nov  5 01:42:35 2024\n",
      "Epoch: 7 Step: 790 Loss: 0.3419 Accuracy: 0.6348 Tue Nov  5 01:42:39 2024\n",
      "Epoch: 7 Step: 800 Loss: 0.3399 Accuracy: 0.6348 Tue Nov  5 01:42:43 2024\n",
      "Epoch: 7 Step: 810 Loss: 0.3398 Accuracy: 0.6348 Tue Nov  5 01:42:46 2024\n",
      "Epoch: 7 Step: 820 Loss: 0.3421 Accuracy: 0.6348 Tue Nov  5 01:42:50 2024\n",
      "Epoch: 7 Step: 830 Loss: 0.3404 Accuracy: 0.6348 Tue Nov  5 01:42:54 2024\n",
      "Epoch: 7 Step: 840 Loss: 0.3367 Accuracy: 0.6348 Tue Nov  5 01:42:57 2024\n",
      "Epoch: 7 Step: 850 Loss: 0.3393 Accuracy: 0.6348 Tue Nov  5 01:43:01 2024\n",
      "Epoch: 7 Step: 860 Loss: 0.3405 Accuracy: 0.6348 Tue Nov  5 01:43:05 2024\n",
      "Epoch: 7 Step: 870 Loss: 0.3381 Accuracy: 0.6349 Tue Nov  5 01:43:08 2024\n",
      "Epoch: 7 Step: 880 Loss: 0.3380 Accuracy: 0.6349 Tue Nov  5 01:43:12 2024\n",
      "Epoch: 7 Step: 890 Loss: 0.3408 Accuracy: 0.6349 Tue Nov  5 01:43:16 2024\n",
      "Epoch: 7 Step: 900 Loss: 0.3414 Accuracy: 0.6349 Tue Nov  5 01:43:19 2024\n",
      "Epoch: 7 Step: 910 Loss: 0.3414 Accuracy: 0.6349 Tue Nov  5 01:43:23 2024\n",
      "Epoch: 7 Step: 920 Loss: 0.3406 Accuracy: 0.6349 Tue Nov  5 01:43:27 2024\n",
      "Epoch: 7 Step: 930 Loss: 0.3424 Accuracy: 0.6349 Tue Nov  5 01:43:30 2024\n",
      "Epoch: 7 Step: 940 Loss: 0.3396 Accuracy: 0.6349 Tue Nov  5 01:43:34 2024\n",
      "Epoch: 7 Step: 950 Loss: 0.3409 Accuracy: 0.6349 Tue Nov  5 01:43:37 2024\n",
      "Epoch: 7 Step: 960 Loss: 0.3398 Accuracy: 0.6349 Tue Nov  5 01:43:41 2024\n",
      "Epoch: 7 Step: 970 Loss: 0.3411 Accuracy: 0.6349 Tue Nov  5 01:43:45 2024\n",
      "Epoch: 7 Step: 980 Loss: 0.3395 Accuracy: 0.6349 Tue Nov  5 01:43:49 2024\n",
      "Epoch: 7 Step: 990 Loss: 0.3385 Accuracy: 0.6349 Tue Nov  5 01:43:52 2024\n",
      "Epoch: 7 Step: 1000 Loss: 0.3403 Accuracy: 0.6349 Tue Nov  5 01:43:56 2024\n",
      "Epoch: 7 Step: 1010 Loss: 0.3377 Accuracy: 0.6349 Tue Nov  5 01:43:59 2024\n",
      "Epoch: 7 Step: 1020 Loss: 0.3396 Accuracy: 0.6349 Tue Nov  5 01:44:03 2024\n",
      "Epoch: 7 Step: 1030 Loss: 0.3402 Accuracy: 0.6349 Tue Nov  5 01:44:07 2024\n",
      "Epoch: 7 Model saved in Loss:  0.34031644\n",
      "Epoch(validation): 7 Val loss:  0.34040385 Accuracy:  0.6348805\n",
      "Epoch: 8 Step: 0 Loss: 0.3386 Accuracy: 0.6394 Tue Nov  5 01:44:11 2024\n",
      "Epoch: 8 Step: 10 Loss: 0.3416 Accuracy: 0.6338 Tue Nov  5 01:44:15 2024\n",
      "Epoch: 8 Step: 20 Loss: 0.3382 Accuracy: 0.6346 Tue Nov  5 01:44:19 2024\n",
      "Epoch: 8 Step: 30 Loss: 0.3382 Accuracy: 0.6351 Tue Nov  5 01:44:22 2024\n",
      "Epoch: 8 Step: 40 Loss: 0.3408 Accuracy: 0.6345 Tue Nov  5 01:44:26 2024\n",
      "Epoch: 8 Step: 50 Loss: 0.3410 Accuracy: 0.6342 Tue Nov  5 01:44:30 2024\n",
      "Epoch: 8 Step: 60 Loss: 0.3407 Accuracy: 0.6342 Tue Nov  5 01:44:33 2024\n",
      "Epoch: 8 Step: 70 Loss: 0.3393 Accuracy: 0.6342 Tue Nov  5 01:44:37 2024\n",
      "Epoch: 8 Step: 80 Loss: 0.3424 Accuracy: 0.6342 Tue Nov  5 01:44:41 2024\n",
      "Epoch: 8 Step: 90 Loss: 0.3412 Accuracy: 0.6342 Tue Nov  5 01:44:44 2024\n",
      "Epoch: 8 Step: 100 Loss: 0.3416 Accuracy: 0.6343 Tue Nov  5 01:44:48 2024\n",
      "Epoch: 8 Step: 110 Loss: 0.3416 Accuracy: 0.6345 Tue Nov  5 01:44:52 2024\n",
      "Epoch: 8 Step: 120 Loss: 0.3420 Accuracy: 0.6346 Tue Nov  5 01:44:56 2024\n",
      "Epoch: 8 Step: 130 Loss: 0.3412 Accuracy: 0.6346 Tue Nov  5 01:44:59 2024\n",
      "Epoch: 8 Step: 140 Loss: 0.3383 Accuracy: 0.6347 Tue Nov  5 01:45:03 2024\n",
      "Epoch: 8 Step: 150 Loss: 0.3409 Accuracy: 0.6347 Tue Nov  5 01:45:07 2024\n",
      "Epoch: 8 Step: 160 Loss: 0.3396 Accuracy: 0.6347 Tue Nov  5 01:45:10 2024\n",
      "Epoch: 8 Step: 170 Loss: 0.3406 Accuracy: 0.6346 Tue Nov  5 01:45:14 2024\n",
      "Epoch: 8 Step: 180 Loss: 0.3420 Accuracy: 0.6347 Tue Nov  5 01:45:18 2024\n",
      "Epoch: 8 Step: 190 Loss: 0.3408 Accuracy: 0.6347 Tue Nov  5 01:45:21 2024\n",
      "Epoch: 8 Step: 200 Loss: 0.3429 Accuracy: 0.6346 Tue Nov  5 01:45:25 2024\n",
      "Epoch: 8 Step: 210 Loss: 0.3395 Accuracy: 0.6346 Tue Nov  5 01:45:29 2024\n",
      "Epoch: 8 Step: 220 Loss: 0.3393 Accuracy: 0.6347 Tue Nov  5 01:45:32 2024\n",
      "Epoch: 8 Step: 230 Loss: 0.3392 Accuracy: 0.6348 Tue Nov  5 01:45:36 2024\n",
      "Epoch: 8 Step: 240 Loss: 0.3404 Accuracy: 0.6347 Tue Nov  5 01:45:39 2024\n",
      "Epoch: 8 Step: 250 Loss: 0.3408 Accuracy: 0.6348 Tue Nov  5 01:45:43 2024\n",
      "Epoch: 8 Step: 260 Loss: 0.3403 Accuracy: 0.6348 Tue Nov  5 01:45:47 2024\n",
      "Epoch: 8 Step: 270 Loss: 0.3404 Accuracy: 0.6348 Tue Nov  5 01:45:50 2024\n",
      "Epoch: 8 Step: 280 Loss: 0.3399 Accuracy: 0.6348 Tue Nov  5 01:45:54 2024\n",
      "Epoch: 8 Step: 290 Loss: 0.3396 Accuracy: 0.6348 Tue Nov  5 01:45:58 2024\n",
      "Epoch: 8 Step: 300 Loss: 0.3397 Accuracy: 0.6348 Tue Nov  5 01:46:01 2024\n",
      "Epoch: 8 Step: 310 Loss: 0.3397 Accuracy: 0.6348 Tue Nov  5 01:46:05 2024\n",
      "Epoch: 8 Step: 320 Loss: 0.3391 Accuracy: 0.6349 Tue Nov  5 01:46:08 2024\n",
      "Epoch: 8 Step: 330 Loss: 0.3401 Accuracy: 0.6349 Tue Nov  5 01:46:12 2024\n",
      "Epoch: 8 Step: 340 Loss: 0.3417 Accuracy: 0.6348 Tue Nov  5 01:46:16 2024\n",
      "Epoch: 8 Step: 350 Loss: 0.3421 Accuracy: 0.6348 Tue Nov  5 01:46:19 2024\n",
      "Epoch: 8 Step: 360 Loss: 0.3396 Accuracy: 0.6348 Tue Nov  5 01:46:23 2024\n",
      "Epoch: 8 Step: 370 Loss: 0.3379 Accuracy: 0.6347 Tue Nov  5 01:46:27 2024\n",
      "Epoch: 8 Step: 380 Loss: 0.3404 Accuracy: 0.6347 Tue Nov  5 01:46:30 2024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Step: 390 Loss: 0.3407 Accuracy: 0.6347 Tue Nov  5 01:46:34 2024\n",
      "Epoch: 8 Step: 400 Loss: 0.3398 Accuracy: 0.6347 Tue Nov  5 01:46:38 2024\n",
      "Epoch: 8 Step: 410 Loss: 0.3386 Accuracy: 0.6348 Tue Nov  5 01:46:41 2024\n",
      "Epoch: 8 Step: 420 Loss: 0.3416 Accuracy: 0.6348 Tue Nov  5 01:46:45 2024\n",
      "Epoch: 8 Step: 430 Loss: 0.3399 Accuracy: 0.6347 Tue Nov  5 01:46:48 2024\n",
      "Epoch: 8 Step: 440 Loss: 0.3407 Accuracy: 0.6347 Tue Nov  5 01:46:52 2024\n",
      "Epoch: 8 Step: 450 Loss: 0.3404 Accuracy: 0.6347 Tue Nov  5 01:46:56 2024\n",
      "Epoch: 8 Step: 460 Loss: 0.3381 Accuracy: 0.6347 Tue Nov  5 01:46:59 2024\n",
      "Epoch: 8 Step: 470 Loss: 0.3414 Accuracy: 0.6347 Tue Nov  5 01:47:03 2024\n",
      "Epoch: 8 Step: 480 Loss: 0.3421 Accuracy: 0.6347 Tue Nov  5 01:47:07 2024\n",
      "Epoch: 8 Step: 490 Loss: 0.3415 Accuracy: 0.6347 Tue Nov  5 01:47:10 2024\n",
      "Epoch: 8 Step: 500 Loss: 0.3388 Accuracy: 0.6347 Tue Nov  5 01:47:14 2024\n",
      "Epoch: 8 Step: 510 Loss: 0.3412 Accuracy: 0.6347 Tue Nov  5 01:47:18 2024\n",
      "Epoch: 8 Step: 520 Loss: 0.3374 Accuracy: 0.6347 Tue Nov  5 01:47:21 2024\n",
      "Epoch: 8 Step: 530 Loss: 0.3403 Accuracy: 0.6347 Tue Nov  5 01:47:25 2024\n",
      "Epoch: 8 Step: 540 Loss: 0.3377 Accuracy: 0.6347 Tue Nov  5 01:47:28 2024\n",
      "Epoch: 8 Step: 550 Loss: 0.3387 Accuracy: 0.6347 Tue Nov  5 01:47:32 2024\n",
      "Epoch: 8 Step: 560 Loss: 0.3395 Accuracy: 0.6348 Tue Nov  5 01:47:36 2024\n",
      "Epoch: 8 Step: 570 Loss: 0.3405 Accuracy: 0.6348 Tue Nov  5 01:47:39 2024\n",
      "Epoch: 8 Step: 580 Loss: 0.3398 Accuracy: 0.6348 Tue Nov  5 01:47:43 2024\n",
      "Epoch: 8 Step: 590 Loss: 0.3399 Accuracy: 0.6348 Tue Nov  5 01:47:47 2024\n",
      "Epoch: 8 Step: 600 Loss: 0.3402 Accuracy: 0.6348 Tue Nov  5 01:47:50 2024\n",
      "Epoch: 8 Step: 610 Loss: 0.3421 Accuracy: 0.6348 Tue Nov  5 01:47:54 2024\n",
      "Epoch: 8 Step: 620 Loss: 0.3406 Accuracy: 0.6348 Tue Nov  5 01:47:58 2024\n",
      "Epoch: 8 Step: 630 Loss: 0.3400 Accuracy: 0.6348 Tue Nov  5 01:48:01 2024\n",
      "Epoch: 8 Step: 640 Loss: 0.3382 Accuracy: 0.6348 Tue Nov  5 01:48:05 2024\n",
      "Epoch: 8 Step: 650 Loss: 0.3410 Accuracy: 0.6348 Tue Nov  5 01:48:09 2024\n",
      "Epoch: 8 Step: 660 Loss: 0.3385 Accuracy: 0.6348 Tue Nov  5 01:48:12 2024\n",
      "Epoch: 8 Step: 670 Loss: 0.3383 Accuracy: 0.6348 Tue Nov  5 01:48:16 2024\n",
      "Epoch: 8 Step: 680 Loss: 0.3411 Accuracy: 0.6348 Tue Nov  5 01:48:19 2024\n",
      "Epoch: 8 Step: 690 Loss: 0.3407 Accuracy: 0.6348 Tue Nov  5 01:48:23 2024\n",
      "Epoch: 8 Step: 700 Loss: 0.3418 Accuracy: 0.6349 Tue Nov  5 01:48:27 2024\n",
      "Epoch: 8 Step: 710 Loss: 0.3406 Accuracy: 0.6349 Tue Nov  5 01:48:30 2024\n",
      "Epoch: 8 Step: 720 Loss: 0.3423 Accuracy: 0.6348 Tue Nov  5 01:48:34 2024\n",
      "Epoch: 8 Step: 730 Loss: 0.3385 Accuracy: 0.6349 Tue Nov  5 01:48:38 2024\n",
      "Epoch: 8 Step: 740 Loss: 0.3393 Accuracy: 0.6349 Tue Nov  5 01:48:41 2024\n",
      "Epoch: 8 Step: 750 Loss: 0.3402 Accuracy: 0.6349 Tue Nov  5 01:48:45 2024\n",
      "Epoch: 8 Step: 760 Loss: 0.3420 Accuracy: 0.6349 Tue Nov  5 01:48:49 2024\n",
      "Epoch: 8 Step: 770 Loss: 0.3390 Accuracy: 0.6349 Tue Nov  5 01:48:52 2024\n",
      "Epoch: 8 Step: 780 Loss: 0.3420 Accuracy: 0.6349 Tue Nov  5 01:48:56 2024\n",
      "Epoch: 8 Step: 790 Loss: 0.3405 Accuracy: 0.6349 Tue Nov  5 01:49:00 2024\n",
      "Epoch: 8 Step: 800 Loss: 0.3424 Accuracy: 0.6349 Tue Nov  5 01:49:03 2024\n",
      "Epoch: 8 Step: 810 Loss: 0.3406 Accuracy: 0.6349 Tue Nov  5 01:49:07 2024\n",
      "Epoch: 8 Step: 820 Loss: 0.3388 Accuracy: 0.6349 Tue Nov  5 01:49:10 2024\n",
      "Epoch: 8 Step: 830 Loss: 0.3399 Accuracy: 0.6349 Tue Nov  5 01:49:14 2024\n",
      "Epoch: 8 Step: 840 Loss: 0.3395 Accuracy: 0.6349 Tue Nov  5 01:49:18 2024\n",
      "Epoch: 8 Step: 850 Loss: 0.3403 Accuracy: 0.6349 Tue Nov  5 01:49:21 2024\n",
      "Epoch: 8 Step: 860 Loss: 0.3405 Accuracy: 0.6349 Tue Nov  5 01:49:25 2024\n",
      "Epoch: 8 Step: 870 Loss: 0.3398 Accuracy: 0.6349 Tue Nov  5 01:49:28 2024\n",
      "Epoch: 8 Step: 880 Loss: 0.3399 Accuracy: 0.6349 Tue Nov  5 01:49:32 2024\n",
      "Epoch: 8 Step: 890 Loss: 0.3384 Accuracy: 0.6349 Tue Nov  5 01:49:36 2024\n",
      "Epoch: 8 Step: 900 Loss: 0.3398 Accuracy: 0.6349 Tue Nov  5 01:49:40 2024\n",
      "Epoch: 8 Step: 910 Loss: 0.3401 Accuracy: 0.6349 Tue Nov  5 01:49:43 2024\n",
      "Epoch: 8 Step: 920 Loss: 0.3396 Accuracy: 0.6349 Tue Nov  5 01:49:47 2024\n",
      "Epoch: 8 Step: 930 Loss: 0.3396 Accuracy: 0.6349 Tue Nov  5 01:49:51 2024\n",
      "Epoch: 8 Step: 940 Loss: 0.3395 Accuracy: 0.6349 Tue Nov  5 01:49:54 2024\n",
      "Epoch: 8 Step: 950 Loss: 0.3421 Accuracy: 0.6349 Tue Nov  5 01:49:58 2024\n",
      "Epoch: 8 Step: 960 Loss: 0.3394 Accuracy: 0.6349 Tue Nov  5 01:50:01 2024\n",
      "Epoch: 8 Step: 970 Loss: 0.3406 Accuracy: 0.6349 Tue Nov  5 01:50:05 2024\n",
      "Epoch: 8 Step: 980 Loss: 0.3403 Accuracy: 0.6349 Tue Nov  5 01:50:09 2024\n",
      "Epoch: 8 Step: 990 Loss: 0.3413 Accuracy: 0.6349 Tue Nov  5 01:50:12 2024\n",
      "Epoch: 8 Step: 1000 Loss: 0.3395 Accuracy: 0.6349 Tue Nov  5 01:50:16 2024\n",
      "Epoch: 8 Step: 1010 Loss: 0.3410 Accuracy: 0.6349 Tue Nov  5 01:50:20 2024\n",
      "Epoch: 8 Step: 1020 Loss: 0.3396 Accuracy: 0.6349 Tue Nov  5 01:50:24 2024\n",
      "Epoch: 8 Step: 1030 Loss: 0.3419 Accuracy: 0.6349 Tue Nov  5 01:50:27 2024\n",
      "Epoch: 8 Model saved in Loss:  0.34031644\n",
      "Epoch(validation): 8 Val loss:  0.3404442 Accuracy:  0.6347825\n",
      "Epoch: 9 Step: 0 Loss: 0.3382 Accuracy: 0.6406 Tue Nov  5 01:50:32 2024\n",
      "Epoch: 9 Step: 10 Loss: 0.3398 Accuracy: 0.6353 Tue Nov  5 01:50:35 2024\n",
      "Epoch: 9 Step: 20 Loss: 0.3381 Accuracy: 0.6359 Tue Nov  5 01:50:39 2024\n",
      "Epoch: 9 Step: 30 Loss: 0.3435 Accuracy: 0.6353 Tue Nov  5 01:50:43 2024\n",
      "Epoch: 9 Step: 40 Loss: 0.3439 Accuracy: 0.6347 Tue Nov  5 01:50:46 2024\n",
      "Epoch: 9 Step: 50 Loss: 0.3406 Accuracy: 0.6343 Tue Nov  5 01:50:50 2024\n",
      "Epoch: 9 Step: 60 Loss: 0.3395 Accuracy: 0.6343 Tue Nov  5 01:50:53 2024\n",
      "Epoch: 9 Step: 70 Loss: 0.3419 Accuracy: 0.6345 Tue Nov  5 01:50:57 2024\n",
      "Epoch: 9 Step: 80 Loss: 0.3402 Accuracy: 0.6348 Tue Nov  5 01:51:01 2024\n",
      "Epoch: 9 Step: 90 Loss: 0.3401 Accuracy: 0.6347 Tue Nov  5 01:51:04 2024\n",
      "Epoch: 9 Step: 100 Loss: 0.3396 Accuracy: 0.6347 Tue Nov  5 01:51:08 2024\n",
      "Epoch: 9 Step: 110 Loss: 0.3423 Accuracy: 0.6346 Tue Nov  5 01:51:11 2024\n",
      "Epoch: 9 Step: 120 Loss: 0.3384 Accuracy: 0.6347 Tue Nov  5 01:51:15 2024\n",
      "Epoch: 9 Step: 130 Loss: 0.3376 Accuracy: 0.6348 Tue Nov  5 01:51:19 2024\n",
      "Epoch: 9 Step: 140 Loss: 0.3411 Accuracy: 0.6348 Tue Nov  5 01:51:22 2024\n",
      "Epoch: 9 Step: 150 Loss: 0.3394 Accuracy: 0.6348 Tue Nov  5 01:51:26 2024\n",
      "Epoch: 9 Step: 160 Loss: 0.3394 Accuracy: 0.6348 Tue Nov  5 01:51:29 2024\n",
      "Epoch: 9 Step: 170 Loss: 0.3414 Accuracy: 0.6348 Tue Nov  5 01:51:33 2024\n",
      "Epoch: 9 Step: 180 Loss: 0.3391 Accuracy: 0.6349 Tue Nov  5 01:51:37 2024\n",
      "Epoch: 9 Step: 190 Loss: 0.3386 Accuracy: 0.6349 Tue Nov  5 01:51:40 2024\n",
      "Epoch: 9 Step: 200 Loss: 0.3394 Accuracy: 0.6349 Tue Nov  5 01:51:44 2024\n",
      "Epoch: 9 Step: 210 Loss: 0.3421 Accuracy: 0.6350 Tue Nov  5 01:51:47 2024\n",
      "Epoch: 9 Step: 220 Loss: 0.3404 Accuracy: 0.6349 Tue Nov  5 01:51:51 2024\n",
      "Epoch: 9 Step: 230 Loss: 0.3409 Accuracy: 0.6349 Tue Nov  5 01:51:55 2024\n",
      "Epoch: 9 Step: 240 Loss: 0.3408 Accuracy: 0.6349 Tue Nov  5 01:51:58 2024\n",
      "Epoch: 9 Step: 250 Loss: 0.3400 Accuracy: 0.6349 Tue Nov  5 01:52:02 2024\n",
      "Epoch: 9 Step: 260 Loss: 0.3405 Accuracy: 0.6349 Tue Nov  5 01:52:05 2024\n",
      "Epoch: 9 Step: 270 Loss: 0.3409 Accuracy: 0.6349 Tue Nov  5 01:52:09 2024\n",
      "Epoch: 9 Step: 280 Loss: 0.3406 Accuracy: 0.6349 Tue Nov  5 01:52:13 2024\n",
      "Epoch: 9 Step: 290 Loss: 0.3398 Accuracy: 0.6349 Tue Nov  5 01:52:16 2024\n",
      "Epoch: 9 Step: 300 Loss: 0.3401 Accuracy: 0.6348 Tue Nov  5 01:52:20 2024\n",
      "Epoch: 9 Step: 310 Loss: 0.3381 Accuracy: 0.6349 Tue Nov  5 01:52:23 2024\n",
      "Epoch: 9 Step: 320 Loss: 0.3399 Accuracy: 0.6349 Tue Nov  5 01:52:27 2024\n",
      "Epoch: 9 Step: 330 Loss: 0.3410 Accuracy: 0.6348 Tue Nov  5 01:52:30 2024\n",
      "Epoch: 9 Step: 340 Loss: 0.3412 Accuracy: 0.6348 Tue Nov  5 01:52:34 2024\n",
      "Epoch: 9 Step: 350 Loss: 0.3411 Accuracy: 0.6348 Tue Nov  5 01:52:38 2024\n",
      "Epoch: 9 Step: 360 Loss: 0.3382 Accuracy: 0.6348 Tue Nov  5 01:52:41 2024\n",
      "Epoch: 9 Step: 370 Loss: 0.3405 Accuracy: 0.6348 Tue Nov  5 01:52:45 2024\n",
      "Epoch: 9 Step: 380 Loss: 0.3396 Accuracy: 0.6347 Tue Nov  5 01:52:48 2024\n",
      "Epoch: 9 Step: 390 Loss: 0.3429 Accuracy: 0.6348 Tue Nov  5 01:52:52 2024\n",
      "Epoch: 9 Step: 400 Loss: 0.3437 Accuracy: 0.6347 Tue Nov  5 01:52:56 2024\n",
      "Epoch: 9 Step: 410 Loss: 0.3429 Accuracy: 0.6347 Tue Nov  5 01:52:59 2024\n",
      "Epoch: 9 Step: 420 Loss: 0.3421 Accuracy: 0.6347 Tue Nov  5 01:53:03 2024\n",
      "Epoch: 9 Step: 430 Loss: 0.3411 Accuracy: 0.6347 Tue Nov  5 01:53:06 2024\n",
      "Epoch: 9 Step: 440 Loss: 0.3417 Accuracy: 0.6347 Tue Nov  5 01:53:10 2024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Step: 450 Loss: 0.3391 Accuracy: 0.6347 Tue Nov  5 01:53:14 2024\n",
      "Epoch: 9 Step: 460 Loss: 0.3414 Accuracy: 0.6347 Tue Nov  5 01:53:17 2024\n",
      "Epoch: 9 Step: 470 Loss: 0.3405 Accuracy: 0.6347 Tue Nov  5 01:53:21 2024\n",
      "Epoch: 9 Step: 480 Loss: 0.3393 Accuracy: 0.6347 Tue Nov  5 01:53:24 2024\n",
      "Epoch: 9 Step: 490 Loss: 0.3392 Accuracy: 0.6347 Tue Nov  5 01:53:28 2024\n",
      "Epoch: 9 Step: 500 Loss: 0.3426 Accuracy: 0.6347 Tue Nov  5 01:53:32 2024\n",
      "Epoch: 9 Step: 510 Loss: 0.3421 Accuracy: 0.6347 Tue Nov  5 01:53:35 2024\n",
      "Epoch: 9 Step: 520 Loss: 0.3407 Accuracy: 0.6347 Tue Nov  5 01:53:39 2024\n",
      "Epoch: 9 Step: 530 Loss: 0.3392 Accuracy: 0.6347 Tue Nov  5 01:53:42 2024\n",
      "Epoch: 9 Step: 540 Loss: 0.3383 Accuracy: 0.6347 Tue Nov  5 01:53:46 2024\n",
      "Epoch: 9 Step: 550 Loss: 0.3432 Accuracy: 0.6347 Tue Nov  5 01:53:50 2024\n",
      "Epoch: 9 Step: 560 Loss: 0.3410 Accuracy: 0.6347 Tue Nov  5 01:53:53 2024\n",
      "Epoch: 9 Step: 570 Loss: 0.3387 Accuracy: 0.6347 Tue Nov  5 01:53:57 2024\n",
      "Epoch: 9 Step: 580 Loss: 0.3415 Accuracy: 0.6347 Tue Nov  5 01:54:01 2024\n",
      "Epoch: 9 Step: 590 Loss: 0.3393 Accuracy: 0.6348 Tue Nov  5 01:54:04 2024\n",
      "Epoch: 9 Step: 600 Loss: 0.3418 Accuracy: 0.6347 Tue Nov  5 01:54:08 2024\n",
      "Epoch: 9 Step: 610 Loss: 0.3397 Accuracy: 0.6347 Tue Nov  5 01:54:11 2024\n",
      "Epoch: 9 Step: 620 Loss: 0.3414 Accuracy: 0.6347 Tue Nov  5 01:54:15 2024\n",
      "Epoch: 9 Step: 630 Loss: 0.3413 Accuracy: 0.6347 Tue Nov  5 01:54:19 2024\n",
      "Epoch: 9 Step: 640 Loss: 0.3392 Accuracy: 0.6347 Tue Nov  5 01:54:22 2024\n",
      "Epoch: 9 Step: 650 Loss: 0.3401 Accuracy: 0.6347 Tue Nov  5 01:54:26 2024\n",
      "Epoch: 9 Step: 660 Loss: 0.3389 Accuracy: 0.6348 Tue Nov  5 01:54:29 2024\n",
      "Epoch: 9 Step: 670 Loss: 0.3396 Accuracy: 0.6348 Tue Nov  5 01:54:33 2024\n",
      "Epoch: 9 Step: 680 Loss: 0.3413 Accuracy: 0.6348 Tue Nov  5 01:54:37 2024\n",
      "Epoch: 9 Step: 690 Loss: 0.3402 Accuracy: 0.6348 Tue Nov  5 01:54:40 2024\n",
      "Epoch: 9 Step: 700 Loss: 0.3394 Accuracy: 0.6348 Tue Nov  5 01:54:44 2024\n",
      "Epoch: 9 Step: 710 Loss: 0.3422 Accuracy: 0.6348 Tue Nov  5 01:54:47 2024\n",
      "Epoch: 9 Step: 720 Loss: 0.3401 Accuracy: 0.6348 Tue Nov  5 01:54:51 2024\n",
      "Epoch: 9 Step: 730 Loss: 0.3395 Accuracy: 0.6348 Tue Nov  5 01:54:55 2024\n",
      "Epoch: 9 Step: 740 Loss: 0.3401 Accuracy: 0.6348 Tue Nov  5 01:54:58 2024\n",
      "Epoch: 9 Step: 750 Loss: 0.3393 Accuracy: 0.6348 Tue Nov  5 01:55:02 2024\n",
      "Epoch: 9 Step: 760 Loss: 0.3404 Accuracy: 0.6348 Tue Nov  5 01:55:05 2024\n",
      "Epoch: 9 Step: 770 Loss: 0.3393 Accuracy: 0.6348 Tue Nov  5 01:55:09 2024\n",
      "Epoch: 9 Step: 780 Loss: 0.3402 Accuracy: 0.6349 Tue Nov  5 01:55:13 2024\n",
      "Epoch: 9 Step: 790 Loss: 0.3401 Accuracy: 0.6349 Tue Nov  5 01:55:16 2024\n",
      "Epoch: 9 Step: 800 Loss: 0.3424 Accuracy: 0.6348 Tue Nov  5 01:55:20 2024\n",
      "Epoch: 9 Step: 810 Loss: 0.3425 Accuracy: 0.6348 Tue Nov  5 01:55:23 2024\n",
      "Epoch: 9 Step: 820 Loss: 0.3389 Accuracy: 0.6349 Tue Nov  5 01:55:27 2024\n",
      "Epoch: 9 Step: 830 Loss: 0.3403 Accuracy: 0.6349 Tue Nov  5 01:55:31 2024\n",
      "Epoch: 9 Step: 840 Loss: 0.3414 Accuracy: 0.6349 Tue Nov  5 01:55:34 2024\n",
      "Epoch: 9 Step: 850 Loss: 0.3417 Accuracy: 0.6349 Tue Nov  5 01:55:38 2024\n",
      "Epoch: 9 Step: 860 Loss: 0.3402 Accuracy: 0.6349 Tue Nov  5 01:55:41 2024\n",
      "Epoch: 9 Step: 870 Loss: 0.3376 Accuracy: 0.6349 Tue Nov  5 01:55:45 2024\n",
      "Epoch: 9 Step: 880 Loss: 0.3390 Accuracy: 0.6349 Tue Nov  5 01:55:49 2024\n",
      "Epoch: 9 Step: 890 Loss: 0.3402 Accuracy: 0.6349 Tue Nov  5 01:55:52 2024\n",
      "Epoch: 9 Step: 900 Loss: 0.3404 Accuracy: 0.6349 Tue Nov  5 01:55:56 2024\n",
      "Epoch: 9 Step: 910 Loss: 0.3399 Accuracy: 0.6349 Tue Nov  5 01:55:59 2024\n",
      "Epoch: 9 Step: 920 Loss: 0.3413 Accuracy: 0.6349 Tue Nov  5 01:56:03 2024\n",
      "Epoch: 9 Step: 930 Loss: 0.3385 Accuracy: 0.6349 Tue Nov  5 01:56:07 2024\n",
      "Epoch: 9 Step: 940 Loss: 0.3389 Accuracy: 0.6349 Tue Nov  5 01:56:10 2024\n",
      "Epoch: 9 Step: 950 Loss: 0.3418 Accuracy: 0.6349 Tue Nov  5 01:56:14 2024\n",
      "Epoch: 9 Step: 960 Loss: 0.3392 Accuracy: 0.6349 Tue Nov  5 01:56:18 2024\n",
      "Epoch: 9 Step: 970 Loss: 0.3381 Accuracy: 0.6349 Tue Nov  5 01:56:21 2024\n",
      "Epoch: 9 Step: 980 Loss: 0.3432 Accuracy: 0.6349 Tue Nov  5 01:56:25 2024\n",
      "Epoch: 9 Step: 990 Loss: 0.3393 Accuracy: 0.6349 Tue Nov  5 01:56:28 2024\n",
      "Epoch: 9 Step: 1000 Loss: 0.3384 Accuracy: 0.6349 Tue Nov  5 01:56:32 2024\n",
      "Epoch: 9 Step: 1010 Loss: 0.3396 Accuracy: 0.6349 Tue Nov  5 01:56:36 2024\n",
      "Epoch: 9 Step: 1020 Loss: 0.3400 Accuracy: 0.6349 Tue Nov  5 01:56:39 2024\n",
      "Epoch: 9 Step: 1030 Loss: 0.3408 Accuracy: 0.6349 Tue Nov  5 01:56:43 2024\n",
      "Epoch: 9 Model saved in Loss:  0.34031644\n",
      "Epoch(validation): 9 Val loss:  0.33971715 Accuracy:  0.63652736\n",
      "Epoch: 10 Step: 0 Loss: 0.3417 Accuracy: 0.6314 Tue Nov  5 01:56:48 2024\n",
      "Epoch: 10 Step: 10 Loss: 0.3401 Accuracy: 0.6335 Tue Nov  5 01:56:51 2024\n",
      "Epoch: 10 Step: 20 Loss: 0.3390 Accuracy: 0.6340 Tue Nov  5 01:56:55 2024\n",
      "Epoch: 10 Step: 30 Loss: 0.3403 Accuracy: 0.6348 Tue Nov  5 01:56:58 2024\n",
      "Epoch: 10 Step: 40 Loss: 0.3386 Accuracy: 0.6347 Tue Nov  5 01:57:02 2024\n",
      "Epoch: 10 Step: 50 Loss: 0.3367 Accuracy: 0.6347 Tue Nov  5 01:57:06 2024\n",
      "Epoch: 10 Step: 60 Loss: 0.3416 Accuracy: 0.6345 Tue Nov  5 01:57:09 2024\n",
      "Epoch: 10 Step: 70 Loss: 0.3423 Accuracy: 0.6344 Tue Nov  5 01:57:13 2024\n",
      "Epoch: 10 Step: 80 Loss: 0.3406 Accuracy: 0.6345 Tue Nov  5 01:57:16 2024\n",
      "Epoch: 10 Step: 90 Loss: 0.3389 Accuracy: 0.6345 Tue Nov  5 01:57:20 2024\n",
      "Epoch: 10 Step: 100 Loss: 0.3398 Accuracy: 0.6346 Tue Nov  5 01:57:24 2024\n",
      "Epoch: 10 Step: 110 Loss: 0.3379 Accuracy: 0.6348 Tue Nov  5 01:57:27 2024\n",
      "Epoch: 10 Step: 120 Loss: 0.3410 Accuracy: 0.6348 Tue Nov  5 01:57:31 2024\n",
      "Epoch: 10 Step: 130 Loss: 0.3421 Accuracy: 0.6347 Tue Nov  5 01:57:35 2024\n",
      "Epoch: 10 Step: 140 Loss: 0.3404 Accuracy: 0.6347 Tue Nov  5 01:57:38 2024\n",
      "Epoch: 10 Step: 150 Loss: 0.3412 Accuracy: 0.6348 Tue Nov  5 01:57:42 2024\n",
      "Epoch: 10 Step: 160 Loss: 0.3411 Accuracy: 0.6349 Tue Nov  5 01:57:45 2024\n",
      "Epoch: 10 Step: 170 Loss: 0.3405 Accuracy: 0.6349 Tue Nov  5 01:57:49 2024\n",
      "Epoch: 10 Step: 180 Loss: 0.3420 Accuracy: 0.6349 Tue Nov  5 01:57:53 2024\n",
      "Epoch: 10 Step: 190 Loss: 0.3412 Accuracy: 0.6349 Tue Nov  5 01:57:56 2024\n",
      "Epoch: 10 Step: 200 Loss: 0.3419 Accuracy: 0.6349 Tue Nov  5 01:58:00 2024\n",
      "Epoch: 10 Step: 210 Loss: 0.3378 Accuracy: 0.6350 Tue Nov  5 01:58:03 2024\n",
      "Epoch: 10 Step: 220 Loss: 0.3408 Accuracy: 0.6349 Tue Nov  5 01:58:07 2024\n",
      "Epoch: 10 Step: 230 Loss: 0.3395 Accuracy: 0.6349 Tue Nov  5 01:58:11 2024\n",
      "Epoch: 10 Step: 240 Loss: 0.3397 Accuracy: 0.6349 Tue Nov  5 01:58:14 2024\n",
      "Epoch: 10 Step: 250 Loss: 0.3405 Accuracy: 0.6349 Tue Nov  5 01:58:18 2024\n",
      "Epoch: 10 Step: 260 Loss: 0.3417 Accuracy: 0.6349 Tue Nov  5 01:58:22 2024\n",
      "Epoch: 10 Step: 270 Loss: 0.3409 Accuracy: 0.6348 Tue Nov  5 01:58:25 2024\n",
      "Epoch: 10 Step: 280 Loss: 0.3414 Accuracy: 0.6348 Tue Nov  5 01:58:29 2024\n",
      "Epoch: 10 Step: 290 Loss: 0.3429 Accuracy: 0.6349 Tue Nov  5 01:58:32 2024\n",
      "Epoch: 10 Step: 300 Loss: 0.3387 Accuracy: 0.6348 Tue Nov  5 01:58:36 2024\n",
      "Epoch: 10 Step: 310 Loss: 0.3420 Accuracy: 0.6348 Tue Nov  5 01:58:40 2024\n",
      "Epoch: 10 Step: 320 Loss: 0.3420 Accuracy: 0.6348 Tue Nov  5 01:58:43 2024\n",
      "Epoch: 10 Step: 330 Loss: 0.3410 Accuracy: 0.6348 Tue Nov  5 01:58:47 2024\n",
      "Epoch: 10 Step: 340 Loss: 0.3419 Accuracy: 0.6347 Tue Nov  5 01:58:51 2024\n",
      "Epoch: 10 Step: 350 Loss: 0.3412 Accuracy: 0.6348 Tue Nov  5 01:58:54 2024\n",
      "Epoch: 10 Step: 360 Loss: 0.3396 Accuracy: 0.6348 Tue Nov  5 01:58:58 2024\n",
      "Epoch: 10 Step: 370 Loss: 0.3389 Accuracy: 0.6348 Tue Nov  5 01:59:01 2024\n",
      "Epoch: 10 Step: 380 Loss: 0.3429 Accuracy: 0.6348 Tue Nov  5 01:59:05 2024\n",
      "Epoch: 10 Step: 390 Loss: 0.3402 Accuracy: 0.6347 Tue Nov  5 01:59:09 2024\n",
      "Epoch: 10 Step: 400 Loss: 0.3377 Accuracy: 0.6347 Tue Nov  5 01:59:12 2024\n",
      "Epoch: 10 Step: 410 Loss: 0.3426 Accuracy: 0.6347 Tue Nov  5 01:59:16 2024\n",
      "Epoch: 10 Step: 420 Loss: 0.3407 Accuracy: 0.6347 Tue Nov  5 01:59:19 2024\n",
      "Epoch: 10 Step: 430 Loss: 0.3415 Accuracy: 0.6347 Tue Nov  5 01:59:23 2024\n",
      "Epoch: 10 Step: 440 Loss: 0.3375 Accuracy: 0.6347 Tue Nov  5 01:59:27 2024\n",
      "Epoch: 10 Step: 450 Loss: 0.3372 Accuracy: 0.6347 Tue Nov  5 01:59:30 2024\n",
      "Epoch: 10 Step: 460 Loss: 0.3389 Accuracy: 0.6347 Tue Nov  5 01:59:34 2024\n",
      "Epoch: 10 Step: 470 Loss: 0.3384 Accuracy: 0.6347 Tue Nov  5 01:59:38 2024\n",
      "Epoch: 10 Step: 480 Loss: 0.3388 Accuracy: 0.6347 Tue Nov  5 01:59:41 2024\n",
      "Epoch: 10 Step: 490 Loss: 0.3417 Accuracy: 0.6347 Tue Nov  5 01:59:45 2024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Step: 500 Loss: 0.3398 Accuracy: 0.6347 Tue Nov  5 01:59:48 2024\n",
      "Epoch: 10 Step: 510 Loss: 0.3406 Accuracy: 0.6347 Tue Nov  5 01:59:52 2024\n",
      "Epoch: 10 Step: 520 Loss: 0.3415 Accuracy: 0.6347 Tue Nov  5 01:59:56 2024\n",
      "Epoch: 10 Step: 530 Loss: 0.3403 Accuracy: 0.6347 Tue Nov  5 01:59:59 2024\n",
      "Epoch: 10 Step: 540 Loss: 0.3392 Accuracy: 0.6347 Tue Nov  5 02:00:03 2024\n",
      "Epoch: 10 Step: 550 Loss: 0.3405 Accuracy: 0.6347 Tue Nov  5 02:00:06 2024\n",
      "Epoch: 10 Step: 560 Loss: 0.3402 Accuracy: 0.6347 Tue Nov  5 02:00:10 2024\n",
      "Epoch: 10 Step: 570 Loss: 0.3402 Accuracy: 0.6348 Tue Nov  5 02:00:14 2024\n",
      "Epoch: 10 Step: 580 Loss: 0.3410 Accuracy: 0.6348 Tue Nov  5 02:00:17 2024\n",
      "Epoch: 10 Step: 590 Loss: 0.3431 Accuracy: 0.6348 Tue Nov  5 02:00:21 2024\n",
      "Epoch: 10 Step: 600 Loss: 0.3394 Accuracy: 0.6348 Tue Nov  5 02:00:24 2024\n",
      "Epoch: 10 Step: 610 Loss: 0.3399 Accuracy: 0.6348 Tue Nov  5 02:00:28 2024\n",
      "Epoch: 10 Step: 620 Loss: 0.3394 Accuracy: 0.6348 Tue Nov  5 02:00:32 2024\n",
      "Epoch: 10 Step: 630 Loss: 0.3395 Accuracy: 0.6348 Tue Nov  5 02:00:35 2024\n",
      "Epoch: 10 Step: 640 Loss: 0.3408 Accuracy: 0.6348 Tue Nov  5 02:00:39 2024\n",
      "Epoch: 10 Step: 650 Loss: 0.3436 Accuracy: 0.6347 Tue Nov  5 02:00:42 2024\n",
      "Epoch: 10 Step: 660 Loss: 0.3397 Accuracy: 0.6348 Tue Nov  5 02:00:46 2024\n",
      "Epoch: 10 Step: 670 Loss: 0.3407 Accuracy: 0.6348 Tue Nov  5 02:00:50 2024\n",
      "Epoch: 10 Step: 680 Loss: 0.3417 Accuracy: 0.6348 Tue Nov  5 02:00:53 2024\n",
      "Epoch: 10 Step: 690 Loss: 0.3377 Accuracy: 0.6348 Tue Nov  5 02:00:57 2024\n",
      "Epoch: 10 Step: 700 Loss: 0.3396 Accuracy: 0.6348 Tue Nov  5 02:01:01 2024\n",
      "Epoch: 10 Step: 710 Loss: 0.3406 Accuracy: 0.6348 Tue Nov  5 02:01:04 2024\n",
      "Epoch: 10 Step: 720 Loss: 0.3412 Accuracy: 0.6348 Tue Nov  5 02:01:08 2024\n",
      "Epoch: 10 Step: 730 Loss: 0.3404 Accuracy: 0.6348 Tue Nov  5 02:01:11 2024\n",
      "Epoch: 10 Step: 740 Loss: 0.3411 Accuracy: 0.6348 Tue Nov  5 02:01:15 2024\n",
      "Epoch: 10 Step: 750 Loss: 0.3398 Accuracy: 0.6348 Tue Nov  5 02:01:19 2024\n",
      "Epoch: 10 Step: 760 Loss: 0.3386 Accuracy: 0.6348 Tue Nov  5 02:01:22 2024\n",
      "Epoch: 10 Step: 770 Loss: 0.3367 Accuracy: 0.6349 Tue Nov  5 02:01:26 2024\n",
      "Epoch: 10 Step: 780 Loss: 0.3402 Accuracy: 0.6348 Tue Nov  5 02:01:29 2024\n",
      "Epoch: 10 Step: 790 Loss: 0.3399 Accuracy: 0.6349 Tue Nov  5 02:01:33 2024\n",
      "Epoch: 10 Step: 800 Loss: 0.3404 Accuracy: 0.6348 Tue Nov  5 02:01:37 2024\n",
      "Epoch: 10 Step: 810 Loss: 0.3379 Accuracy: 0.6348 Tue Nov  5 02:01:40 2024\n",
      "Epoch: 10 Step: 820 Loss: 0.3420 Accuracy: 0.6349 Tue Nov  5 02:01:44 2024\n",
      "Epoch: 10 Step: 830 Loss: 0.3398 Accuracy: 0.6349 Tue Nov  5 02:01:48 2024\n",
      "Epoch: 10 Step: 840 Loss: 0.3389 Accuracy: 0.6349 Tue Nov  5 02:01:51 2024\n",
      "Epoch: 10 Step: 850 Loss: 0.3413 Accuracy: 0.6349 Tue Nov  5 02:01:55 2024\n",
      "Epoch: 10 Step: 860 Loss: 0.3394 Accuracy: 0.6349 Tue Nov  5 02:01:59 2024\n",
      "Epoch: 10 Step: 870 Loss: 0.3405 Accuracy: 0.6349 Tue Nov  5 02:02:02 2024\n",
      "Epoch: 10 Step: 880 Loss: 0.3398 Accuracy: 0.6349 Tue Nov  5 02:02:06 2024\n",
      "Epoch: 10 Step: 890 Loss: 0.3399 Accuracy: 0.6348 Tue Nov  5 02:02:09 2024\n",
      "Epoch: 10 Step: 900 Loss: 0.3389 Accuracy: 0.6349 Tue Nov  5 02:02:13 2024\n",
      "Epoch: 10 Step: 910 Loss: 0.3400 Accuracy: 0.6349 Tue Nov  5 02:02:17 2024\n",
      "Epoch: 10 Step: 920 Loss: 0.3404 Accuracy: 0.6349 Tue Nov  5 02:02:20 2024\n",
      "Epoch: 10 Step: 930 Loss: 0.3422 Accuracy: 0.6349 Tue Nov  5 02:02:24 2024\n",
      "Epoch: 10 Step: 940 Loss: 0.3408 Accuracy: 0.6348 Tue Nov  5 02:02:27 2024\n",
      "Epoch: 10 Step: 950 Loss: 0.3393 Accuracy: 0.6349 Tue Nov  5 02:02:31 2024\n",
      "Epoch: 10 Step: 960 Loss: 0.3389 Accuracy: 0.6349 Tue Nov  5 02:02:35 2024\n",
      "Epoch: 10 Step: 970 Loss: 0.3398 Accuracy: 0.6349 Tue Nov  5 02:02:38 2024\n",
      "Epoch: 10 Step: 980 Loss: 0.3384 Accuracy: 0.6349 Tue Nov  5 02:02:42 2024\n",
      "Epoch: 10 Step: 990 Loss: 0.3398 Accuracy: 0.6349 Tue Nov  5 02:02:45 2024\n",
      "Epoch: 10 Step: 1000 Loss: 0.3391 Accuracy: 0.6349 Tue Nov  5 02:02:49 2024\n",
      "Epoch: 10 Step: 1010 Loss: 0.3430 Accuracy: 0.6349 Tue Nov  5 02:02:53 2024\n",
      "Epoch: 10 Step: 1020 Loss: 0.3413 Accuracy: 0.6349 Tue Nov  5 02:02:56 2024\n",
      "Epoch: 10 Step: 1030 Loss: 0.3402 Accuracy: 0.6349 Tue Nov  5 02:03:00 2024\n",
      "Epoch: 10 Model saved in Loss:  0.34031644\n",
      "Epoch(validation): 10 Val loss:  0.34062293 Accuracy:  0.63424575\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 512, 912, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 456, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 456, 32  128        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 456, 64  18496       ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 256, 456, 64  256        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 256, 456, 64  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 256, 456, 12  73856       ['activation[0][0]']             \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 256, 456, 12  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 256, 456, 12  147584      ['batch_normalization_2[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 256, 456, 12  512        ['conv2d_5[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 256, 456, 12  0           ['batch_normalization_3[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 228, 12  8320        ['activation[0][0]']             \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 228, 12  0           ['activation_1[0][0]']           \n",
      "                                8)                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " add (Add)                      (None, 128, 228, 12  0           ['conv2d_3[0][0]',               \n",
      "                                8)                                'max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 128, 228, 12  0           ['add[0][0]']                    \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 128, 228, 25  295168      ['activation_2[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 128, 228, 25  1024       ['conv2d_11[0][0]']              \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 128, 228, 25  0           ['batch_normalization_4[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 128, 228, 25  590080      ['activation_3[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 128, 228, 25  1024       ['conv2d_12[0][0]']              \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 128, 228, 25  33024       ['max_pooling2d[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " average (Average)              (None, 128, 228, 25  0           ['batch_normalization_5[0][0]',  \n",
      "                                6)                                'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 128, 228, 25  0           ['average[0][0]']                \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 128, 228, 25  590080      ['activation_4[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 128, 228, 25  1024       ['conv2d_13[0][0]']              \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 128, 228, 25  0           ['batch_normalization_6[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 128, 228, 25  590080      ['activation_5[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 128, 228, 25  1024       ['conv2d_14[0][0]']              \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " average_1 (Average)            (None, 128, 228, 25  0           ['batch_normalization_7[0][0]',  \n",
      "                                6)                                'conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 64, 114, 256  33024       ['add[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 114, 256  0          ['average_1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 64, 114, 256  0           ['conv2d_9[0][0]',               \n",
      "                                )                                 'max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 64, 114, 256  0           ['add_1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 64, 114, 512  1180160     ['activation_6[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 64, 114, 512  2048       ['conv2d_19[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 64, 114, 512  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 64, 114, 256  33024       ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 64, 114, 512  2359808     ['activation_7[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 64, 114, 256  0           ['conv2d_8[0][0]',               \n",
      "                                )                                 'max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 64, 114, 512  2048       ['conv2d_20[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 64, 114, 512  131584      ['add_2[0][0]']                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " average_2 (Average)            (None, 64, 114, 512  0           ['batch_normalization_9[0][0]',  \n",
      "                                )                                 'conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 64, 114, 512  0           ['average_2[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 64, 114, 512  2359808     ['activation_8[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 64, 114, 512  2048       ['conv2d_21[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 64, 114, 512  0           ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 64, 114, 512  2359808     ['activation_9[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 64, 114, 512  2048       ['conv2d_22[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " average_3 (Average)            (None, 64, 114, 512  0           ['batch_normalization_11[0][0]', \n",
      "                                )                                 'conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 64, 114, 512  0           ['average_3[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 64, 114, 512  2359808     ['activation_10[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 64, 114, 512  2048       ['conv2d_23[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 64, 114, 512  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 64, 114, 512  2359808     ['activation_11[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 64, 114, 512  2048       ['conv2d_24[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " average_4 (Average)            (None, 64, 114, 512  0           ['batch_normalization_13[0][0]', \n",
      "                                )                                 'conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 32, 57, 512)  131584      ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 57, 512)  0          ['average_4[0][0]']              \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 32, 57, 512)  0           ['conv2d_17[0][0]',              \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 32, 57, 512)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 32, 57, 512)  2359808     ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 32, 57, 512)  2048       ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 32, 57, 512)  0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 57, 512)  131584      ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 32, 57, 512)  2359808     ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 32, 57, 512)  0           ['conv2d_10[0][0]',              \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 32, 57, 512)  2048       ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 32, 57, 512)  262656      ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " average_5 (Average)            (None, 32, 57, 512)  0           ['batch_normalization_15[0][0]', \n",
      "                                                                  'conv2d_28[0][0]']              \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 32, 57, 512)  0           ['average_5[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 32, 57, 512)  2359808     ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 32, 57, 512)  2048       ['conv2d_32[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 32, 57, 512)  0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 32, 57, 512)  2359808     ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 32, 57, 512)  2048       ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " average_6 (Average)            (None, 32, 57, 512)  0           ['batch_normalization_17[0][0]', \n",
      "                                                                  'conv2d_28[0][0]']              \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 32, 57, 512)  0           ['average_6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 32, 57, 512)  2359808     ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 32, 57, 512)  2048       ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 32, 57, 512)  0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 32, 57, 512)  2359808     ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 32, 57, 512)  2048       ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " average_7 (Average)            (None, 32, 57, 512)  0           ['batch_normalization_19[0][0]', \n",
      "                                                                  'conv2d_28[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 32, 57, 512)  262656      ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 32, 57, 512)  0           ['average_7[0][0]',              \n",
      "                                                                  'conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 32, 57, 512)  0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 32, 57, 256)  1179904     ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 32, 57, 256)  1024       ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 32, 57, 256)  0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 32, 57, 256)  590080      ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 32, 57, 256)  1024       ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 32, 57, 256)  131328      ['average_7[0][0]']              \n",
      "                                                                                                  \n",
      " average_8 (Average)            (None, 32, 57, 256)  0           ['batch_normalization_21[0][0]', \n",
      "                                                                  'conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 32, 57, 256)  0           ['average_8[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 32, 57, 256)  590080      ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 32, 57, 256)  1024       ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 32, 57, 256)  0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 32, 57, 256)  590080      ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 32, 57, 256)  1024       ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " average_9 (Average)            (None, 32, 57, 256)  0           ['batch_normalization_23[0][0]', \n",
      "                                                                  'conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 32, 57, 256)  0           ['average_9[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 32, 57, 256)  590080      ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 32, 57, 256)  1024       ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 32, 57, 256)  0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 32, 57, 256)  590080      ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 32, 57, 256)  1024       ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " average_10 (Average)           (None, 32, 57, 256)  0           ['batch_normalization_25[0][0]', \n",
      "                                                                  'conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 32, 57, 16)   8208        ['average_7[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 32, 57, 16)   4112        ['average_10[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_7 (Conv2DTran  (None, 64, 114, 16)  65552      ['conv2d_37[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_transpose_11 (Conv2DTra  (None, 64, 114, 16)  65552      ['conv2d_47[0][0]']              \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 64, 114, 16)  8208        ['average_4[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 64, 114, 16)  272         ['conv2d_transpose_7[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 64, 114, 16)  272         ['conv2d_transpose_11[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 128, 228, 16  16400      ['conv2d_25[0][0]']              \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_8 (Conv2DTran  (None, 128, 228, 16  65552      ['conv2d_39[0][0]']              \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_12 (Conv2DTra  (None, 128, 228, 16  65552      ['conv2d_48[0][0]']              \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 128, 228, 16  4112        ['average_1[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 128, 228, 16  272         ['conv2d_transpose_4[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 128, 228, 16  272         ['conv2d_transpose_8[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 128, 228, 16  272         ['conv2d_transpose_12[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 256, 456, 16  4112       ['conv2d_15[0][0]']              \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 256, 456, 16  16400      ['conv2d_26[0][0]']              \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_9 (Conv2DTran  (None, 256, 456, 16  65552      ['conv2d_40[0][0]']              \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_13 (Conv2DTra  (None, 256, 456, 16  65552      ['conv2d_49[0][0]']              \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 256, 456, 1)  65          ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 256, 456, 1)  129         ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 256, 456, 1)  17          ['conv2d_transpose_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 256, 456, 1)  17          ['conv2d_transpose_5[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 256, 456, 16  272         ['conv2d_transpose_9[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 256, 456, 1)  17          ['conv2d_transpose_13[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 512, 912, 1)  5          ['conv2d_4[0][0]']               \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 512, 912, 1)  5          ['conv2d_6[0][0]']               \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 512, 912, 1)  17         ['conv2d_16[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 512, 912, 1)  65         ['conv2d_30[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d_transpose_10 (Conv2DTra  (None, 512, 912, 1)  4097       ['conv2d_42[0][0]']              \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " conv2d_transpose_14 (Conv2DTra  (None, 512, 912, 1)  257        ['conv2d_50[0][0]']              \n",
      " nspose)                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 512, 912, 6)  0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'conv2d_transpose_1[0][0]',     \n",
      "                                                                  'conv2d_transpose_3[0][0]',     \n",
      "                                                                  'conv2d_transpose_6[0][0]',     \n",
      "                                                                  'conv2d_transpose_10[0][0]',    \n",
      "                                                                  'conv2d_transpose_14[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 512, 912, 1)  7           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 512, 912, 1)  4          ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 512, 912, 1)  0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 35,230,798\n",
      "Trainable params: 35,212,684\n",
      "Non-trainable params: 18,114\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train(model,\"dexined_try\",train_data,val_data,0.0001,0.5,11,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pre = read_image('H:\\\\download\\\\blender\\\\projects\\\\vdmTests\\\\outlineOutput2\\\\test\\\\dense_981.png')\n",
    "img = np.expand_dims(img_pre, axis=0)\n",
    "plt.imshow(img_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_e = read_image('H:\\\\download\\\\blender\\\\projects\\\\vdmTests\\\\outlineOutput2\\\\test_edge\\\\dense_981.png')\n",
    "#img = np.expand_dims(img, axis=0)\n",
    "plt.imshow(img_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(\"H:\\\\tmp\\\\dexined\\\\checkpoint_dir\\\\dexined_tryepochs\\\\DexiNed10_model.h5\")\n",
    "res_pre = model.predict(img)\n",
    "res = res_pre[-1,:,:]\n",
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_normalization(img, img_min=0, img_max=255):\n",
    "    \"\"\"This is a typical image normalization function\n",
    "    where the minimum and maximum of the image is needed\n",
    "    source: https://en.wikipedia.org/wiki/Normalization_(image_processing)\n",
    "    :param img: an image could be gray scale or color\n",
    "    :param img_min:  for default is 0\n",
    "    :param img_max: for default is 255\n",
    "    :return: a normalized image, if max is 255 the dtype is uint8\n",
    "    \"\"\"\n",
    "    img = np.float32(img)\n",
    "    epsilon=1e-12 # whenever an inconsistent image\n",
    "    img = (img-np.min(img))*(img_max-img_min)/((np.max(img)-np.min(img))+epsilon)+img_min\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "res2=res\n",
    "res2[res2 < 0.0] = 0.0\n",
    "out=cv2.bitwise_not(np.uint8(image_normalization(res2)))\n",
    "plt.imshow(out, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "executionInfo": {
     "elapsed": 569127,
     "status": "error",
     "timestamp": 1729891994812,
     "user": {
      "displayName": "Stefania Stefanska",
      "userId": "00621967363159764559"
     },
     "user_tz": -120
    },
    "id": "-Su4qagMf8Qt",
    "outputId": "e566425b-7ad3-46c5-8e1b-b4f332190f02"
   },
   "outputs": [],
   "source": [
    "#train_steps=len(train_data)\n",
    "#val_steps=len(test_data)\n",
    "#print(train_steps)\n",
    "#model.fit(train_data, validation_data=test_data, epochs=2, steps_per_epoch=train_steps, validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./DexiNed_batchSize4.h5')\n",
    "img_pre = read_image('outlineOutput/val_edge/dense_981.png')\n",
    "img = np.expand_dims(img_pre, axis=0)\n",
    "#plt.imshow(img_e)\n",
    "res_pre = model.predict(img)\n",
    "res = res_pre[-1,:,:]\n",
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_data, validation_data=test_data, epochs=8, steps_per_epoch=train_steps, validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('./DexiNed.h5')\n",
    "model.save('./DexiNed_train-21K_test-2K_epoch10_batchsize16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pre = read_image('outlineOutput/val/dense_981.png')\n",
    "img = np.expand_dims(img_pre, axis=0)\n",
    "plt.imshow(img_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_e = read_image('outlineOutput/val_edge/dense_981.png')\n",
    "#img = np.expand_dims(img, axis=0)\n",
    "plt.imshow(img_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res[-1,:,:]\n",
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_pre = read_image('BIPED/edges/imgs/train/rgbr/real/RGB_258.jpg')\n",
    "imgg = np.expand_dims(img_pre, axis=0)\n",
    "plt.imshow(img_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "edge_pre = read_image('BIPED/edges/edge_maps/train/rgbr/real/RGB_258.png')\n",
    "#imgg = np.expand_dims(edge_pre, axis=0)\n",
    "plt.imshow(edge_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(imgg)\n",
    "res = res[-1,:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DexiNed_train-21K_test-2K_epoch8_batchsize16\n",
    "model8epoch = tf.keras.models.load_model(\"DexiNed_train-21K_test-2K_epoch8_batchsize16.h5\")\n",
    "img_pre = read_image('outlineOutput/val/dense_981.png')\n",
    "img = np.expand_dims(img_pre, axis=0)\n",
    "res = model8epoch.predict(img)\n",
    "res = res[-1,:,:]\n",
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_pre = read_image('BIPED/edges/imgs/train/rgbr/real/RGB_258.jpg')\n",
    "imgg = np.expand_dims(img_pre, axis=0)\n",
    "resg = model8epoch.predict(imgg)\n",
    "resg = resg[-1,:,:]\n",
    "plt.imshow(resg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(model8epoch.optimizer.iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8epoch.fit(train_data, validation_data=test_data, epochs=10, steps_per_epoch=train_steps, validation_steps=val_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.save('./DexiNed_train-21K_test-2K_epoch20_batchsize16.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.save('./DexiNed_train-21K_test-2K_epoch20_batchsize16.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pre = read_image('BIPED/edges/imgs/train/rgbr/real/RGB_258.jpg')\n",
    "resg = model8epoch.predict(imgg)\n",
    "resg = resg[-1,:,:]\n",
    "plt.imshow(resg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pre = read_image('outlineOutput/val/dense_981.png')\n",
    "img = np.expand_dims(img_pre, axis=0)\n",
    "res = model8epoch.predict(img)\n",
    "res = res[-1,:,:]\n",
    "plt.imshow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pre = read_image('outlineOutput/val/hyl4.jpg')\n",
    "img = np.expand_dims(img_pre, axis=0)\n",
    "res = model8epoch.predict(img)\n",
    "res = res[-1,:,:]\n",
    "plt.imshow(res)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPHvhZlsj853ynbRVQlO4au",
   "gpuType": "T4",
   "mount_file_id": "1hg6ehhBlxibKkFgFALsYuRk0CL30fwy-",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
